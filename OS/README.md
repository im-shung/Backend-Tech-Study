# 운영체제

# 프로세스
## 프로그램과 프로세스 차이
프로그램(prgram)
- 하드디스크 등의 저장 매체에 저장
- 실행 파일의 형태

프로세스(prcess)
- 프로그램이 메모리에 적재되어 실행 중인 상태
  - 필요한 모든 자원을 할당 받는다.
  - 자원이란 코드/데이터/스택/힙 공간을 말한다.

## 프로세스 특징
- 운영체제는 프로그램을 메모리에 적재하고 프로세스로 다룬다.
- 운영체제는 프로세스에게 실행에 필요한 메모리를 할당한다. 이곳에 코드와 데이터 등을 적재한다.
- 프로세스들은 서로 독립적인 메모리 공간을 가진다. 다른 프로세스의 영역에 접근 불가능.

## 프로세스 관리
프로세스 생성에서 종료까지 관리는 모두 커널에 의해 이루어진다. 커널 영역에 프로세스 테이블을 만들고, 프로세스의 목록을 관리한다.

관리 내용
- 프로세스 생성/실행/일시중단/재개/중단
- 프로세스 정보 관리
  - 프로세스의 메모리 위치
  - 크기 
- 프로세스마다 고유한 번호(프로세스 ID)를 할당
- 프로세스 통신
- 프로세스 동기화
- 프로세스 컨텍스트 스위칭

## 프로그램의 다중 인스턴스
한 프로그램을 여러 번 실행시켜 다중 인스턴스를 생성할 수 있다. 운영체제는 프로그램을 실행할 때마다 독립된 프로세스를 생성한다. 각 프로세스는 독립된 메모리 공간이 할당된다. 

## 프로세스를 구성한 4개의 메모리 영역
### 코드(code) 영역
실행될 프로그램 코드가 적재되는 영역
- 사용자가 작성한 모든 함수 코드
- 사용자가 호출한 라이브러리 함수 코드

### 데이터(data) 영역
프로그램에서 고정적으로 만든 변수 공간으로 프로세스 적재 시 할당, 종료 시 소멸된다.
- 전역 변수 공간
- 정적 데이터 공간
- (사용자 프로그램과 라이브러리 포함)

### 힙(heap) 영역
프로세스가 실행 도중 동적으로 사용할 수 있도록 할당된 공간
- malloc() 등으로 할당받은 공간
  
힙 영역에서 아래 번지로 내려가며 할당된다.

### 스택(stack) 영역
함수가 실행될 때 사용될 데이터를 위해 할당된 공간
- 매개변수
- 지역변수
- 리턴값

함수는 호출될 때, 스택 영역에서 위쪽으로 공간을 할당한다. 함수가 return 하면 할당된 공간이 반환된다. 함수 호출 외에 프로세스에서 필요 시 사용가능하다.

## 프로세스 주소 공간
프로세스가 실행 중에 접근할 수 있도록 허용된 주소의 최대 범위이다. 

프로세스 주소 공간은 논리 공간(가상 공간)이다. 0번지에서 시작하여 연속적인 주소를 갖는다.

프로세스 주소 공간은 CPU가 액세스할 수 있는 전체 크기이다. (32 비트 CPU의 경우, 4GB)

### 프로세스 공간과 프로세스 현재 크기
프로세스 주소 공간의 크기는 프로세스의 현재 크기와 다르다.
- 프로세스 주소 공간 크기: 프로세스가 액세스할 수 있는 최대 크기
- 프로세스 현재 크기: 적재된 코드 + 전역 변수 + 힙 영역에서 할당받아 사용중인 동적 메모리 공간 + 현재 스택 영역에 저장된 데이터 크기

### 사용자 공간과 커널 공간
프로세스 주소 공간은 2부분으로 나뉘어진다.

사용자 공간
- 프로세스의 코드, 데이터, 힙, 스택 영역이 할당되는 공간
- 코드와 데이터 영역의 크기는 프로세스 시작 시 결정된다.
- 힙과 스택의 영역 크기는 정해져 있지 않다.
- 힙 영역은 아래로 자라고, 스택은 위로 자란다.
  
커널 공간
- 프로세스가 시스템 호출을 통해 이용하는 커널 공간
- 커널 코드, 커널 데이터, 커널 스택(커널이 실행될 때)
- 커널 공간은 모든 사용자 프로세스에 의해 공유된다.
  
### 가상 공간
프로세스 주소 공간은 사용자나 개발자가 보는 관점이다.
- 자신이 작성한 프로그램이 0번지부터 시작하여
- 연속적인 메모리 공간에 형성되고,
- CPU가 액세스할 수 있는 최대 크기의 메모리가 설치되어 있다고 상상

실제 상황
- 실제 물리 메모리 크기는 프로세스 주소 공간보다 작을 수 있다.
- 프로세스의 코드, 데이터, 힙, 스택 영역은 물리 메모리에 흩어져 저장된다. 연속적인 메모리 공간이 아니다.

# 커널의 프로세스 관리
## 프로세스 테이블과 프로세스 제어 블록
프로세스 테이블(Process Table) : 시스템의 모든 프로세스들을 관리하기 위한 표
- 시스템에 1개만 존재한다.
- 구현 방식은 OS마다 다르다.

프로세스 제어 블록(Process Control Block, PCB) : 프로세스에 관한 정보를 저장하는 구조체
- 프로세스당 1개씩 존재
- 프로세스가 생성될 때 만들어지고 종료되면 삭제된다.
- 커널에 의해 생성되고 저장, 읽혀지는 등 관리된다.

프로세스 테이블과 프로세스 제어 블록의 위치
- 커널 영역, 커널 코드(커널 모드)만이 액세스 가능

# 프로세스 생명 주기와 상태 변이(state change)
## 프로세스의 생명 주기
프로세스는 탄생에서 종료까지 여러 상태로 바뀌면서 실행된다.

<img src="../imgs/os-state-change.png">

## 프로세스의 상태
### New [생성 상태]
- 프로세스가 생성된 상태
- 메모리 할당 및 필요한 자원을 적재한다.

### Ready [준비 상태]
- 프로세스가 스케줄링을 기다리는 준비 상태
- 프로세스는 준비 큐에서 대기한다.
- [dispatch] 스케줄링되면 Running 상태로 바뀌고 CPU에 의해 실행된다.

### Running [실행 상태]
- 프로세스가 CPU에 의해 현재 실행되고 있는 상태
- [timeout] CPU의 시간할당량(타임슬라이스,time slice)가 지나면 다시 Ready 상태로 바뀌고 준비 큐에 삽입된다.
- [block] 프로세스가 입출력을 시행하면 커널은 프로세스를 Blocked 상태로 만들고 대기 큐에 삽입한다.

### Blocked/Wait [블록 상태]
- 프로세스가 자원을 요청하거나, 입출력 요청하고(시스템 호출) 완료를 기다리는 상태
- [wakeup] 입출력이 완료되면 프로세스는 Ready 상태로 바뀌고 준비 큐에 삽입된다.

### Terminated/Zombie 상태
- 프로세스가 종료된 상태
- 프로세스가 차지하고 있던 메모리와 할당받았던 자원을 모두 반환(열어 놓은 파일 닫힘)
- Zombie 상태: 프로세스의 PCB에 남긴 종료코드를 부모 프로세스가 읽어가지 않아 완전히 종료되지 않은 상태
  - 프로세스의 테이블 항목과 PCB가 시스템에 여전히 남아있는 상태

### Terminated/Out 상태
- 프로세스가 종료하면서 남긴 종료코드를 부모 프로세스가 읽어가서 완전히 종료된 상태
- 프로세스 테이블의 항목과 PCB가 시스템에서 완전히 제거된 상태

## 프로세스 스케줄링과 컨텍스트 스위칭 
과거 OS의 실행단위는 프로세스였다. Ready 상태의 프로세스 중 실행 시킬 프로세스를 선택했다.

오늘날 OS의 실행단위는 스레드다. Ready 상태의 스레드 중 실행 시킬 스레드를 선택한다.

프로세스는 스레드들에게 공유 자원을 제공하는 컨테이너(Container)로 역할이 바뀌었다. 

# Process vs Thread
<img src="../imgs/os-thread.png">

Process
- 실행 중인 프로그램으로, 디스크로부터 메모리에 적재되어 운영체제로부터 주소 공간, 파일, 메모리 등을 할당 받음
- 함수의 매개변수, 복귀 주소, 로컬 변수와 같은 임시 자료를 저장하는 프로세스 스택과 전역 변수들을 저장하는 데이터 섹션, 프로세스 실행 중에 동적으로 할당받는 메모리 힙을 포함
- 특정 프로세스에 대한 중요한 정보를 저장하고 있는 운영체제의 자료구조를 PCB(Process Control Block)라고 하며, 운영체제는 프로세스 생성과 동시에 고유한 PCB를 생성하여 프로세스를 관리

Thread
- 프로세스의 실행 단위. 한 프로세스 내에서 동작되는 여러 실행 흐름으로 프로세스 내의 Heap, Data, Code 영역을 공유
- 각각의 스레드는 독립적인 작업을 수행해야 하기 때문에 각자의 스택과 PC Register 값을 가지고 있음

```
스택을 스레드마다 독립적으로 할당하는 이유

- 스택은 함수 호출 시 전달되는 인자, 되돌아 갈 주소값 및 함수 내에서 선언하는 변수 등을 저장하기 위해 사용되는 메모리 공간이다. 

- 스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능하다는 것이다. 스레드의 정의에 따라 독립적인 실행 흐름을 가지기 위한 최소 조건으로 독립된 스택을 할당한다.
```

<hr>

출처
- [프로세스와 스레드 : Process vs. Thread](https://eun-jeong.tistory.com/19)

<hr>

# 인터럽트 
## 인터럽트란
프로세서가 현재 실행을 일시 중단하고 발생한 인터럽트를 서비스하도록 요청하는 신호이다. 인터럽트를 서비스하기 위해, 프로세서는 대응하는 인터럽트 서비스 루틴(ISR)을 실행한다. 인터럽트 서비스 루틴의 실행 후에, 프로세서는 정지된 프로그램의 실행을 재개한다. 

## 인터럽트가 필요한 이유
### 선점형 스케줄러 구현
프로세스를 교체하기 위해 스케줄러가 Running 상태인 프로세스를 중지시켜야 함

### IO Device와의 상호작용
저장 매체에서 데이터 처리 완료 시, 프로세스를 깨워야 함 (wakeup)

### 예외 상황 핸들링 
CPU가 프로그램을 실행하고 있을 때, 입출력 하드웨어 등의 장치나 예외상황이 발생할 경우, CPU가 해당 처리를 할 수 있도록 CPU에게 알려야 함

## 인터럽트 종류
### 하드웨어 인터럽트
장치들이 CPU에게 어떤 상황 발생을 알리는 하드웨어 신호다. 인터럽트가 발생하면 CPU는 인터럽트 서비스 루틴을 실행한다.
- I/O interrupt
- timer interrupt
- Maskable interrupt: 프로세서가 더 높은 우선순위로 프로그램을 실행할 경우 무시되거나 지연될 수 있다.
- Non Maskable interrupt: 무시되거나 지연될 수 없으며 프로세서에 의해 즉시 서비스되어야 한다.

### 소프트웨어 인터럽트
소프트웨어 인터럽트는 조건이 충족되거나 시스템 호출이 발생할 때 발생하는 인터럽트다. 어떤 경우에는 소프트웨어 인터럽트가 설계상이 아닌 프로그램 실행 오류에 의해 예기치 않게 발생할 수 있다. 이러한 인터럽트를 exceptions 또는 traps라고 한다. 

## 인터럽트 발생 처리 과정
<img src="../imgs/Instruction-Cycle-with-Interrupts.jpg">

일반적인 명령 주기는 명령 가져오기 및 실행으로 시작합니다. 그러나, 명령어의 정상적인 처리 중에 인터럽트가 발생하는 것을 수용하기 위해, 그림과 같이 인터럽트 사이클을 정상적인 명령 사이클에 추가한다.

현재 명령이 실행된 후, 프로세서는 인터럽트 신호를 확인하여 보류 중인 인터럽트가 있는지 확인합니다. 보류 중인 인터럽트가 없으면 프로세서는 시퀀스의 다음 명령을 가져오기 위해 계속한다. 

프로세서가 보류 중인 인터럽트를 발견하면, 실행되어야 하는 다음 명령어의 주소를 저장함으로써 현재 프로그램의 실행을 중단하고 프로그램 카운터(PC)를 인터럽트 서비스 루틴의 시작 주소로 업데이트하여 발생한 인터럽트를 서비스한다. 인터럽트가 완전히 서비스된 후 프로세서는 중단된 프로그램의 실행을 다시 시작합니다.

### 인터럽트 신호 허용
IE 플래그가 1로 설정되면 프로세서는 발생한 인터럽트를 허용합니다. IE 플래그가 0으로 설정된 경우 요청된 인터럽트를 무시합니다.

## 인터럽트 vs 폴링
폴링은 컴퓨터 시스템의 마이크로 컨트롤러가 모든 장치의 상태를 지속적으로 확인하는 지속적인 모니터링 상태이다. 마이크로 컨트롤러가 폴링을 하는 동안 다른 작업을 수행할 수 없기 때문에 낭비가 크다. 인터럽트를 사용하면 컨트롤러가 장치의 상태를 정기적으로 모니터링 할 필요가 없다. 인터럽트가 발생할 때만 응답하면 된다. 

<hr>

출처
- [Interrupts in Computer Architecture](https://binaryterms.com/interrupts-in-computer-architecture.html)
- [interrupt](https://www.techtarget.com/whatis/definition/interrupt)
- [인터럽트(Interrupt)란?](https://whatisthenext.tistory.com/147)

<hr>

# 캐시의 지역성(Locality)
## 캐시 메모리란
캐싱(caching)은 컴퓨터의 처리 성능을 높이기 위한 기법이다. CPU는 데이터를 처리하기 위해 메모리에 끊임없이 액세스 하는데, CPU에 비해 메모리 속도가 느려 CPU가 효율적으로 사용되지 못한다. 이를 해결하기 위해 CPU와 메모리 사이에 캐시를 두어 CPU의 메모리 액세스 횟수를 줄인다.

## 캐시 적중과 실패
캐시 메모리가 있는 컴퓨터 시스템은 CPU는 메모리에 접근하기 전에 캐시 메모리를 먼저 확인한다. 이때 필요한 데이터가 있는 경우 <strong>적중(hit)</strong>, 없는 경우를 <strong>실패(miss)</strong>라고 한다.

캐시에 저장할 데이터는 지역성을 가져야하는데 지역성이란 데이터 접근이 시간적 혹은 공간적으로 가깝게 일어나는 것을 말한다.

요청한 데이터를 캐시 메모리에서 찾을 확률을 <strong>적중률(hit ratio)</strong>라고 한다. 

캐시 메모리의 성능은 적중률에 의해 결정된다.
```
         캐시 메모리의 적중 횟수
적중률 = -----------------------
         전체 메모리의 참조 횟수
```

캐시 메모리의 적중 여부는 <strong>참조의 지역성(Locality of reference)</strong> 원리에 달려있다. 지역성이란 기억장치 내의 정보를 균일하게 접근하는 것이 아닌 어느 한 순간에 특성 부분을 집중적으로 참조하는 특성이다.

## 지역성의 종류
### 시간적 지역성(Temporal Locality)
특정 데이터가 한번 접근되었을 경우, 가까운 미래에 또 한번 데이터에 접근할 가능성이 높은 것.

메모리 상의 같은 주소에 여러 차례 읽기 쓰기를 수행할 경우, 상대적으로 작은 크기의 캐시를 사용해 효율성을 높일 수 있다.


### 공간적 지역성(Spatial Locality)
특정 데이터와 가까운 주소가 순서대로 접근되었을 경우.

CPU 캐시나 디스크 캐시의 경우 한 메모리 주소에 접근할 때 그 주소 뿐 아니라 해당 블록을 전부 캐시에 가져오게 된다. 이때 메모리 주소를 오름차순이나 내림차순으로 접근하면 캐시에 이미 저장된 같은 블록의 데이터를 접근하게 되므로 캐시 효율성이 향상된다.

### 순차적 지역성(Sequential Locality)
분기가 발생하지 않는 한 명령어는 메모리에 저장된 순서대로 인출/실행된다.

<hr>

출처
- [캐시 메모리(cache memory)의 개요 정리](https://zion830.tistory.com/46)
- [Caching Locality와 Cache Hit Ratio에 대해 설명하시오](https://github.com/lunchScreen/Interview_Questions/issues/98)

<hr>

# 뮤텍스와 세마포어 차이
## 임계영역과 상호배제
```
임계영역(Critical Section): 여러 프로세스가 데이터를 공유하며 수행될 때, 각 프로세스에서 공유 데이터를 접근하는 프로그램 코드 블록
```
```
상호 배제(Mutual Exclution): 임계 구역을 어느 시점에서 단지 한 개의 프로세스만이 사용할 수 있도록 하며, 다른 프로세스가 현재 사용 중인 임계 구역에 대하여 접근하려고 할 때 이를 금지하는 행위
```

프로세스 간 메시지를 전송하거나, 공유메모리를 통해 공유된 자원에 여러 개의 프로세스가 동시에 접근하면 임계영역 문제가 발생할 수 있다. 이를 해결하기 위해 <strong>데이터를 한 번에 하나의 프로세스만 접근할 수 있도록 제한을 두는 동기화 방식</strong>을 취해야 한다. 

동기화 도구에는 대표적으로 뮤텍스(Mutex)와 세마포어(Semaphore)가 있다. 이들은 모두 공유된 자원의 데이터를 여러 스레드/프로세스가 접근하는 것을 막는 역할을 한다.

## 뮤텍스 (Mutex)
공유된 자원의 데이터 혹은 임계영역(Critical Section) 등에 <strong>하나의 Process 혹은 Thread</strong>가 접근하는 것을 막아준다. 

-> 즉, 동기화 대상이 하나

임계영역(Critical Section)을 가진 스레드들의 실행시간(Running Time)이 서로 겹치치 않고 각각 단독으로 실행(상호배제)되도록 하는 기술이다. 

<img src="../imgs/os-mutex.png">

한 프로세스에 의해 소유될 수 있는 <strong>key를 기반으로 한 상호배제 기법</strong>이다. key에 해당하는 어떤 객체(object)가 있으며, <strong>이 객체를 소유한 스레드/프로세스만이 공유자원에 접근</strong>할 수 있다. 

다중 프로세스들의 공유 자원에 대한 접근을 조율하기 위해 <strong>동기화(Synchronization) 또는 락(Lock)</strong>을 사용함으로써 <strong>뮤텍스 객체를 두 스레드가 동시에 사용할 수 없다.</strong>

## 세마포어 (Semaphore)
공유된 자원의 데이터 혹은 임계영역(Critical Section) 등에 <strong>여러 Process 혹은 Thread</strong>가 접근하는 것을 막아준다. 

-> 즉, 동기화 대상이 하나 이상

<img src="../imgs/os-semaphore.png">

사용하고 있는 스레드/프로세스의 수를 <strong>공통으로 관리하는 하나의 값</strong>을 이용해 상호배제를 달성한다. 공유자원에 접근할 수 있는 <strong>프로세스의 최대 허용치만큼 동시에 사용자가 접근</strong>할 수 있으며, <strong>각 프로세스는 세마포어의 값을 확인하고 변경</strong>할 수 있다. 

자원을 사용하지 않는 상태가 될 때, 대기하던 프로세스가 즉시 자원을 사용한다. 이미 다른 프로세스에 의해 사용 중이라는 사실을 알게 되면, 재시도 전에 일정시간 대기해야 한다.

## 차이점
가장 큰 차이점은 <strong>동기화 대상의 개수</strong>이다.

Mutex
- 동기화 대상이 오직 1개일 때 사용한다.
- 자원을 소유하고 책임을 갖는다.
- 상태가 0, 1 뿐이므로 Lock을 가질 수 있고, 소유하고 있는 스레드만이 Mutex를 해제할 수 있다.
- 프로세스의 범위를 가지며 프로세스 종료될 때 자동으로 Clean up 된다.

Semaphore
- 동기화 대상이 1개 이상일 때 사용한다.
- 자원 소유가 불가하다.
- Semaphore를 소유하지 않는 스레드가 Semaphore를 해제할 수 있다.
- 시스템 범위에 걸쳐 있고, 파일 시스템 상의 파일로 존재한다.


## 결론
뮤텍스와 세마포어 모두 완벽한 기법은 아니므로, 데이터 무결성을 보장할 수 없고 모든 교착상태를 해결하지 못한다. 하지만 상호배제를 위한 기본적인 문법이며 여기에 좀 더 복잡한 매커니즘을 적용해 개선된 성능을 가질 수 있도록 하는 것이 중요하다.

<hr>

출처
- [Mutex 뮤텍스와 Semaphore 세마포어의 차이](https://heeonii.tistory.com/14)

<hr>

# 동기(Sync)와 비동기(Async) 차이
## 동기(Synchronous: 동시에 일어나는)
- 단일 스레드 모델
- 작업이 하나씩 순서대로 수행된다.
- 첫번째 작업이 완료되야지 다음 작업이 수행된다. 
- 블로킹 아키텍처로 반응성 시스템 프로그래밍에 적합하다.
- ex) 전화 

## 비동기(Asynchronous : 동시에 일어나지 않는)
- 멀티 스레드 모델
- 하나 이상의 작업이 진행되는 동안 추가적인 작업을 차단하지 않는다.
- 다른 작업이 완료될 때까지 기다리지 않고 여러 관련 작업을 동시에 실행할 수 있다.
- 함수가 호출될 때부터 함수의 값이 반환될 때까지의 지연 시간을 줄인다. 
  - 사용자는 자신의 앱이 빠르게 실행되기를 원하지만, API에서 데이터를 가져오는 데는 시간이 걸린다. 이러한 경우 비동기식 프로그래밍은 앱 화면이 더 빨리 로드되도록 도와주어 사용자 경험을 향상시킨다. 
- 논블로킹 아키텍처로 네트워킹 및 통신 프로그래밍에 적합하다.
- ex) 문자 메시지


## 차이점
Sync
- 단일 스레드로 한 번에 하나의 작업/프로그램만 실행된다.
- 서버에 한 번에 하나의 요청만 보내고, 해당 요청이 서버에 의해 응답될 때까지 기다린다.
- 속도가 느리지만 체계적이다.

Async
- 멀티 스레드로 여러 작업이나 프로그램이 병렬로 실행된다.
- 서버에 여러 요청을 전송한다.
- 여러 작업을 동시에 실행할 수 있어 처리량이 증가한다.

<hr>

출처
- [Asynchronous vs. Synchronous Programming](https://www.mendix.com/blog/asynchronous-vs-synchronous-programming/)

<hr>

# 멀티 스레드 프로그래밍
## 멀티 스레딩(Multi-threading)이란?
<img src="../imgs/os-multithreadingprogramming.jpg">

- 하나의 프로세스를 다수의 실행 단위로 구분하여 자원을 공유하고 자원의 생성과 관리의 중복성을 최소화하여 수행 능력을 향상 시키는 것
- 하나의 프로그램에서 동시에 여러 개의 일을 수행할 수 있도록 해줌(사실 분산처리를 통해 동시에 실행되는 것 처럼 보이는 것)
  - ex) 워드 프로세서에서 그림을 표시하고, 키 입력에 응답하며 철자 및 문법 검사를 계속 함
  
    <img src="../imgs/os-multithreading.jpg">

## 장점
### 1. 응답성
프로그램의 일부분(스레드)이 중단되거나 긴 작업을 수행하더라도, 프로그램의 수행이 계속 되어 사용자에 대한 응답성이 증가한다.

ex) 멀티 스레드가 적용된 웹 브라우저 프로그램에서 하나의 스레드가 이미지 파일을 로드하고 있는 동안, 다른 스레드에서 사용자와 상호작용 가능

### 2. 경제성
프로세스 내 자원들과 메모리를 공유하기 때문에 메모리 공간과 시스템 자원소모가 줄어든다. 스레드 간 통신이 필요한 경우에도 쉽게 데이터를 주고 받을 수 있으며, 프로세스의 context switching과 달리 스레드 간 context switching은 캐시 메모리를 비울 필요가 없기 때문에 더 빠르다.

### 3. 멀티프로세서 활용
다중 CPU 구조에서는 각각의 스레드가 다른 프로세서에서 병렬로 수행될 수 있으므로 병렬성이 증가한다.

## 단점
### 1. 임계 영역
공유하는 자원에 동시 접근하는 경우, 프로세스와 달리 스레드는 데이터와 힙 영역을 공유하기 때문에 어떤 스레드가 다른 스레드에서 사용 중인 변수나 자료구조에 접근하여 엉뚱한 값을 읽어오거나 수정할 수 있다. 따라서 동기화가 필요하다.

### 2. 동기화
동기화를 통해 스레드의 작업 처리 순서와 공유 자원에 대한 접근을 컨트롤 할 수 있다. 그러나 불필요한 부분까지 동기화 하는 경우, 과도한 lock으로 인해 병목 현상을 발생시켜 성능이 저하될 가능성이 높기 때문에 주의해야 한다.
동기화 방법에는 뮤텍스와 세마포어가 있다.

### 3. context switching
동기화 등의 이유로 싱글 코어 멀티 스레딩은 스레드 생성 시간이 오히려 오버헤드로 작용해 단일 스레드보다 느리다. 

<hr>

출처
- [멀티스레드 : Multi-thread (장단점, 멀티프로세스와 차이)](https://eun-jeong.tistory.com/20)

<hr>

# 메모리 단편화 해결
## 메모리 관리 문제
### 배경 키워드
프로세스
- 독립된 메모리 공간을 갖는다
- 독립된 메모리이기 때문에 다른 프로세스의 메모리 공간에 일반적으로 접근할 수 없다.

운영체제
- 메모리의 커널 공간과 사용자 공간의 접근에 제약 받지 않는다.

Swapping
- 메모리 관리를 위해 사용되는 기법이다.
  - 예를 들어 CPU 할당 시간이 끝난 프로세스의 메모리를 HDD 같은 보조 기억장치로 내보내고 다른 프로세스의 메모리를 불러 들일 수 있다.

Swap-in
- 주 기억장치(RAM)로 불러오는 과정

Swap-out
- 보조 기억장치로 내보내는 과정
  
단편화(Fragmentation)
- 메모리 적재&제거가 반복되면서 프로세스들이 차지하는 메모리 틈 사이에 사용하지 못할 만큼의 작은 자유 공간들을 의미한다.
- '외부 단편화'와 '내부 단편화' 두 가지 종류로 나뉜다.

### 외부 단편화
물리 메모리(RAM)에서 할당할 수 없는 작은 공간들이 생기는 것을 말한다.

```
RAM 외부 단편화
|   프로세스A   |free|  프로세스B  |free| 프로세스C |free|    	프로세스D    |
```
free를 하나로 모으면 다른 프로세스를 할당할 수 있지만, 각각 분산되어 있어 프로세스를 불러올 수 없다. 이 분산된 상태를 외부 단편화라 한다.

-> 압축을 통해 해결하기도 한다.

압축이란 프로세스 사용 공간을 한쪽으로 몰아 자유공간을 확보하는 것이다. 하지만 작업 효율이 좋지 않다.

### 내부 단편화
프로세스가 사용하는 메모리 공간 안에 남는 부분을 말한다.
```
프로세스 A의 내부 공간
|       9,999B       |2B|
```
프로세스 내 메모리 공간이 10,000B일 때, 그 안에서 9,999B 사용하면 2B라는 메모리가 남게되고, 이 현상을 내부 단편화라 한다.

## 매모리 단편화 해결 방법
### 1. 페이징 (Paging) - 가상 메모리 사용, 외부 단편화 해결 
프로세스를 일정 크기로 잘게 쪼개어 순서와 상관없이 적재하는 방식이다. 

<img src="../imgs/os-paging.png">

물리 메모리(Frame)안에 프로세스의 논리 메모리(Page)들이 고정된 크기의 블록으로 적재된다. ( => 프로세스를 일정한 크기인 Page로 잘라서 메모리에 적재하는 방식)

배치 순서는 상관없기 때문에 메모리 공간을 연속된 순서로 차지하지 않아 외부 단편화 문제를 해결한다.

단점은 내부 단편화 문제의 비중이 늘어난다.

### 2. 세그먼테이션 (Segmentation) - 가상 메모리 사용, 내부 단편화 해결
페이징과 다르게 고정된 크기가 아닌 서로 다른 크기의 논리적인 단위인 세그먼트로 분할하는 방식이다.

<img src="../imgs/os-segment.png">

page 처럼 크기가 동일하지 않기 때문에 세그먼트 번호와 시작 주소(base), 세그먼트 크기(limit)를 갖는다.

단점은 서로 다른 크기의 세그먼트들이 메모리에 적재되고 제거되는 일이 반복되다 보면, 작은 조각의 자유 공간들이 많아지면서 외부 단편화 문제가 발생한다.

### 3. 메모리 풀 (Memory Pool) - 내부 단편화, 외부 단편화 해결
고정된 크기의 블록을 할당하여 메모리 동적 할당을 가능하게 해준다. memory pool이라 불리는 동일한 사이즈의 메모리 블록들을 미리 할당해 놓고 프로세스들이 필요할 때마다 사용하고 반납하는 기법이다. (=> 미리 할당하기 때문에 메모리 누수가 있다.)

미리 공간을 할당해놓고 사용한 다음 반납하기 때문에 이로 인한 외부 단편화 문제는 발생하지 않는다. 또한 필요한 크기만큼 할당하기 때문에 내부 단편화도 존재하지 않는다.

메모리의 할당, 해제가 빈번할 때는 메모리 풀 방식이 효과적이다.

### 4. 압축(Compaction)
메모리 공간들을 재배치 하여, 단편화로 인해 분산되어 있는 메모리 공간들을 하나로 합치는 기법이다.

```
|프로세스|  free  |프로세스|프로세스|프로세스| free | 
⬇️
|프로세스|프로세스|프로세스|프로세스|   free   |    
```

### 5. 통합(Coalescing)
단편화로 인해 분산된 메모리공간들을 인접해 있는 것끼리 통합시켜 큰 메모리 공간으로 합치는 기법이다. 압축은 재배치가 일어나지만 통합은 인접한 공간들끼리 통합된다는 차이가 있다.

```
|프로세스|프로세스|프로세스|프로세스|   free   |    
⬇️
|프로세스|프로세스|프로세스|  free  |   free   |    
⬇️
|프로세스|프로세스|프로세스|     free     |    
```

<hr>

출처
- [메모리 단편화를 해결하는 세 가지 방법](https://daco2020.tistory.com/174)
- [메모리 압축(compaction)과 메모리 통합(coalescing)](https://m.blog.naver.com/qbxlvnf11/221367174686)

<hr>

# 가상 메모리 
가상 메모리는 메모리 관리 기법 중 하나로, 기계에 실제로 이용 가능한 자원을 추상화하여 사용자들에게 매우 큰 메모리인 것 처럼 보이게 만든다. 즉, 프로그램에 실제 메모리 주소가 아닌 가상 메모리 주소를 주는 방식이다.

<img src="../imgs/os-demandpaging.png">

- 논리 주소(가상 주소): 가상적으로 주어진 주소
- 물리 주소: 실제 메모리 상에서 유효한 주소

논리 주소는 <strong>주소 변환을 담당하는 하드웨어인 MMU</strong>(메모리 관리 장치: Memory Management Unit)에 의해 물리 주소로 변환된다.

### 가상 메모리 장점 
- 사용자 프로그램이 물리 메모리보다 커져도 된다. 즉, 물리적 메모리의 제약을 벗어나게 해준다.
- 시스템이 더 많은 프로세스를 수용할 수 있게 해준다.
- CPU 이용률과 처리율이 높아진다.
- 프로그램을 메모리에 올리고 스왑 하는 필요한 입출력 횟수가 줄어든다.

## 요구 페이징
요구 페이징은 프로그램 실행 시 프로세스를 구성하는 모든 페이지를 한꺼번에 메모리에 올리는 것이 아니라, 당장 사용될 페이지만을 올리는 방식이다. 따라서 요구 페이징 기법에서는 특정 페이지에 대해 CPU의 요청이 들어온 뒤 해당 페이지를 메모리에 적재한다.

## 페이지 부재 (Page Fault)
가상 메모리 기법(요구 페이징)은 일부 페이지만 메모리에 적재되어 있고 나머지는 디스크의 swap 영역에 존재한다. 이러한 이유로 메모리에 페이지가 존재하는지 구별하기 위해 valid-invalid bit를 두어 각 페이지가 존재하는지 표시한다.

이때, <strong>페이지가 메모리에 적재되지 않아</strong> valid-invalid bit에 invalid로 세팅되어 있는 경우를 <strong>페이지 폴트</strong>가 일어났다고 한다. 

### 페이지 부재 (Page Fault) 처리 과정

<img src="../imgs/os-pagefault.png">

CPU가 invalid 페이지에 접근하면 주소 변환을 담당하는 하드웨어인 MMU(Memory Management Unit)가 페이지 부재 트랩(Page Fault Trap)을 발생시킨다. (=> 인터럽트 발생)

다음으로 CPU의 제어권이 커널모드로 변경되고, 운영체제의 페이지 폴트 인터럽트 서비스 루틴이 호출된다.

1. 운영체제가 해당 페이지에 접근하기 위해 주소가 유효한지 확인한다.
2. 범위가 벗어나는 영역에 속한 페이지 접근이나 접근 권한을 위반할 경우 프로세스를 종료시킨다.
3. 접근이 가능한 경우 물리 메모리에 비어있는 프레임을 할당받는다.
4. 비어 있는 프레임이 없다면 기존에 메모리에 올라와 있는 페이지 중 하나를 디스크로 보낸다.(swap-out)
5. 디스크로부터 메모리 적재는 오랜 시간이 걸린다. 따라서 페이지 폴트가 발생한 프로세스는 CPU를 반납하고 PCB에 현재 상태를 저장한 후 block 상태가 된다.
6. 디스크 입출력이 완료되어 인터럽트가 발생되면, 해당 페이지의 valid-invalid bit를 valid로 수정한다.
7. block 된 프로세스를 준비 큐로 이동시킨다.
8. CPU를 할당받고 PCB로부터 저장된 값을 복원시켜 중단되었던 명령부터 실행을 이어간다.

<hr>

출처
- [요구 페이징(가상메모리)](https://zangzangs.tistory.com/142)
- [가상메모리(Virtual Memory)와 요구 페이징(Demand Paging), Valid-Invalid Bit, 페이지 부재(Page Fault)과정](https://code-lab1.tistory.com/59)

<hr>

# 임계구역과 상호배제
스레드 동기화는 공유 데이터를 사용하려고 다수의 스레드가 경쟁하는 경우, 먼저 접근한 스레드가 공유 데이터를 배타적으로 사용하도록 다른 스레드가 접근하지 못하게 상호 협력(coordination)하는 것이다. 여기서, 스레드 동기화와 관련하여 반드시 알아야 할 중요한 다음 2개의 용어가 있다.
```
임계 구역과 상호배제
```
<strong>사용자가 작성한 프로그램 중 공유 데이터에 접근하는 일부의 코드들</strong>을 임계구역(critical section)이라고 부른다. 그리고 <strong>다수의 스레드로부터 공유 데이터의 훼손을 막기 위해 임계구역은 반드시 한 스레드만 배타적 독점적으로 실행하도록 관리</strong>되어야 한다. 이를 상호배제(mutual exclusion)라고 부른다. 상호배제의 핵심은 임계구역에 먼저 진입한 스레드가 임계구역의 실행을 끝낼 때까지 다른 스레드가 진입하지 못하도록 보장하는 것이다. 상호배제의 장치가 없는 임계구역은 있을 수 없다. 임계구역 설정은 멀티스레드 응용프로그램 개발자의 판단에 따라 이루어진다. 개발자 스스로 공유 데이터를 액세스하는 코드 블록을 임계구역으로 묶고, 임계구역에 대한 상호배제가 이루어지도록 작성해야 한다. 이러한 작업들은 일반적으로 멀티스레드 라이브러리나 시스템 호출을 이용하여 작성한다.
```
thread-safe와 thread-unsafe
공유 데이터가 여러 스레드에 의한 동시 접근에도 훼손되지 않게 유지될 때 'thread-safe'라고 한다. 공유 데이터에 대한 스레드의 동기화가 잘 구현되어 있다는 뜻이다. 예를 들어 자바에서 Vector 클래스는 thread-safe하다. 여러 자바 스레드들이 하나의 Vector 객체를 동시에 사용해도 스레드 동기화가 이루어지도록 Vector 클래스가 작성되어 있다는 뜻이다. 반면 자바의 ArrayList 클래스는 thread-unsafe하여 멀티 스레드에 의해 사용되면 문제가 발생할 수 있다. 한편, ArrayList는 데이터를 넣고 뺄 때마다 동기화 기능을 수행하는 긴 코드를 가진 Vector보다 속도가 빨라 단일 스레드 응용 프로그램에게는 유리하다.
```

## 임계구역 문제
### 해결 조건
임계 구역 문제를 해결하기 위해서는 다음 3가지 조건을 충족해야 한다.
1. 상호배제(mutual exclusion)
   - 하나의 프로세스가 임계 구역에 들어가 있다면 다른 프로세스는 들어갈 수 없어야 한다.
2. 진행(progress)
   - 임계 구역에 들어간 프로세스가 없는 상태에서, 들어가려고 하는 프로세스가 여러 개 있다면 어느 것이 들어갈지를 적절히 결정해주어야 한다.
3. 한정 대기(bounded waiting)
   - 다른 프로세스의 기아(Starvation)를 방지하기 위해, 한 번 임계 구역에 들어간 프로세스는 다음 번 임계 구역에 들어갈 때 제한을 두어야 한다.

### 해결 방법
- 소프트웨어적 방법 - Peterson's 알고리즘 등
- 하드웨어적 방법 - 인터럽트 서비스 금지, 원자 명령 활용

소프트웨어적 방법과 하드웨어적 방법으로 나눌 수 있다. 소프트웨어적인 방법(Peterson's 알고리즘 등)은 알고리즘 수준에서 제시된 것들로 실제 구현에 있어 여러 문제를 노출하기 때문에, 오늘 날에는 하드웨어적 방법(원자명령)을 사용한다. 임계구역의 상호배제는 '임계구역의 진입코드(entry 코드)와 진출코드(exit 코드)'를 어떻게 구현하느냐가 관건이다.

## 상호배제 구현 방법 - 원자명령(atomic instruction)
원자명령이란 두 명령 사이에 컨텍스트 스위칭이 일어나지 않도록 두 명령을 하나의 명령으로 만드는 것이다. 원자명령은 TSL(Test and Set Lock)라고도 부른다. 개발자는 다양한 동기화 라이브러리를 통해 구현할 수 있다. 

```
모든 CPU 명령은 원자적인데 TSL을 특별히 원자명령이라고 부르는 이유
모든 기계 명령은 원자적이어서 CPU가 기계 명령을 실행하는 도중 중단하는 일은 없다. CPU는 명령을 실행 중일 때 인터럽트가 발생한다고 하더라도, 현재 실행 중인 기계 명령을 실행한 후 인터럽트를 서비스한다. 하나의 기계 명령을 실행되는 도중에는 컨텍스트 스위칭이 결코 일어날 수 없다. 이렇듯 모든 기계 명령은 원자적이다. 그럼에도 불구하고 TSL을 원자명령이라고 명명한 것은, 2개의 명령을 합쳐 1개의 명령으로 만들고 TSL 명령 실행 중간에 인터럽트 서비스나 컨텍스트 스위칭이 발생하지 못하도록 하였다는 것이다.
```

<hr>

출처
- [임계 구역 문제](https://ko.wikipedia.org/wiki/%EC%9E%84%EA%B3%84_%EA%B5%AC%EC%97%AD_%EB%AC%B8%EC%A0%9C)

<hr>

# 멀티스레드 동기화 기법
동기화 기법들은 겉으로 드러나지는 않지만, 임계구역에 진입할 때 상호배제를 위해 원자명령을 사용한다.
- 락(lock) 방식: 뮤텍스(mutex), 스핀락(spinlock)
- wait-signal 방식: 세마포(semaphore)

락 방식은 하나의 락 변수를 두고, 락을 잠근 스레드만이 임계구역에 진입하는 기법이다. 뮤텍스 기법은 락을 소유하지 않은 스레드를 대기 큐에서 재우고 락이 풀리기를 기다리게 하는 방식이고, 스핀락 기법은 락이 잠겨 있으면 락이 풀릴 때까지 무한 루프를 돌면서 락을 검사하는 코드를 실행하는 기법이다. 세마포는 여러 개의 공유 자원을 여러 스레드가 사용할 수 있도록 관리하는 기법이다.

## 뮤텍스
뮤텍스는 잠김/열림(locked/unlocked) 중 한 상태를 가지는 락 변수를 이용하여, 한 스레드만 임계구역에 진입시키고 다른 스레드들은 큐에 대기시키는 기법이다.
- 변수 - 락 변수
- 연산 - lock 연산과 unlock 연산
- 큐 - 대기 큐(wait queue)

뮤택스는, 락이 걸려 있는 경우 임계구역에 들어가려고 하는 스레드가 락이 풀릴 때까지 블록 상태로 대기 큐에서 잠을 자기 때문에 블록킹 락(blocking lock) 기법이라고도 하고, sleep-waiting lock 기법이라고도 한다.

### 락 변수
락 변수는 true와 false 중 한 값을 가지는 변수이다. 락 변수에 true를 저장하는 것을 '락을 잠근다', '락을 소유한다', 또는 '자원을 소유한다'고 표현한다. 락을 false로 만드는 것을 '락을 연다', '락을 푼다', 혹은 '락을 해제한다' 등으로 표현한다. <strong>락 변수를 true로 만든 스레드만 임계구역을 실행할 수 있다. </strong>

### lock 연산
lock 연산은 임계구역의 entry 코드로서, 락이 잠금(lock=true) 상태이면 현재 스레드를 블록 상태로 만들어 대기 큐에 삽입한다. 락이 잠금 상태가 아니면, 락을 잠그고 임계구역으로 진입한다. lock 연산의 구현에는 원자명령이 사용된다.

### unlock 연산
unlock 연산은 임계구역을 나올 때 실행하는 exit 코드로서, 락을 열림 상태(lock=false)로 변경하고 대기 큐에 있는 스레드 중 하나를 깨워 준비 상태로 만든다.

### 뮤텍스의 특징
임계구역의 실행시간이 짧은 경우, 뮤텍스는 비효율적이다. 락이 잠겨 있는 경우, 스레드는 CPU를 내놓고(컨텍스트 스위칭) 대기 큐로 들어가서 락이 풀리면 다시 CPU를 얻어(컨텍스트 스위칭) 실행된다. 임계구역의 실행시간이 짧으면, 락이 잠겨 있는 시간보다 스레드가 잠자고 깨는데 걸리는 시간 낭비(2번의 컨텍스트 스위칭)가 더 크기 때문에 비효율적이다.

## 스핀락(spinlock)
스핀락도 뮤텍스와 같이 락을 기반으로 하는 동기화 기법이지만, 뮤텍스와 달리 대기 큐가 없다. 
- 변수 - 락 변수
- 연산 - lock 연산과 unlock 연산

스핀락 기법에서, 스레드는 임계구역에 진입하기 위해 lock 연산을 실행한다. lock 연산은 락이 잠겨 있으면 뮤텍스와 달리 무한 루프를 돌며 락이 풀릴 때까지 락을 검사한다. 스레드는 타임 슬라이스가 다하게 되면 컨텍스트 스위칭 되고, 다시 스케줄되면 또 다시 lock 변수가 열림 상태가 될 때까지 루프를 돈다. 그래서 스핀락을 공격적인 뮤텍스(aggressive mutex)라고 한다. 스핀(spin) 용어 역시 락이 풀릴 때까지(자원을 얻을 때까지) 계속 락 변수를 감시하기 때문에 붙여졌다. 뮤텍스 기법을 sleep-waiting lock 기법이라고 하고, 스핀락을 busy-waiting lock 기법이라고 한다.

### 락 변수
스핀락 기법에서 락 변수를 스핀락이라고 한다. 스핀락을 소유한 스레드만 임계구역에 진입할 수 있다.

### lock 연산
lock 연산은 임계구역의 entry 코드로서, 락 변수가 열림 상태이면 락을 잠구고 임계구역에 들어선다. 만일 락이 잠금 상태이면 열릴 때까지 무한 루프를 돈다. 락이 열리면 락을 잠그고 임계구역에 들어간다. lock 연산의 구현에는 원자명령이 사용된다.

### unlock 연산 
unlock 연산은 임계구역을 나올 때 실행하는 exit 코드로서, 락을 열림으로 변경한다.

### 스핀락의 특징
- busy-waiting 모형
- 단일 CPU를 가진 운영체제에서 스핀락은 매우 비효율적이다. T1 스레드가 락을 잠구고 임계구역을 실행한다. CPU가 하나뿐이므로 운영체제는 T1 스레드를 중단시키고 T2를 스케줄링하여 실행시킨다. T2 스레드가 실행되었지만 락이 잠겨 있어, lock 연산은 락이 열림 상태가 될 때까지 락을 검사하는 코드를 실행하므로 계속 CPU를 사용한다. 결국 T2는 타임 슬라이스 내내 의미 없는 기다림에 CPU를 사용하기 때문에, CPU의 낭비가 심하고 다른 스레드의 실행 기회마저 뺐게 된다. 이런 이유로 스핀락은 단일 CPU를 가진 시스템에서 비효율적이다. 이와 대조적으로, 멀티코어 CPU 시스템의 경우, 락을 경쟁하는 스레드들은 서로 다른 코어에서 실행시키면 상당히 효과적이다.
- 스핀락은 임계구역 코드가 짧아서 락이 빨리 풀리는 경우에 매우 효과적이다. 스핀락을 이용하면 2번의 컨텍스트 스위칭(락을 얻지 못한 스레드를 블록시키는 컨텍스트 스위칭과 대기 큐에서 다시 실행시키는 컨텍스트 스위칭)이 필요없고, 이 사이에서 벌어지는 스케줄링 또한 필요없다.
- 스핀락은 스레드들이 락을 얻기 위해 무한 경쟁하기 때문에, 어떤 스레드가 불행하게도 무한 경쟁에서 오랜 동안 락을 얻지 못할 수도 있다. 즉 기아(starvation)를 발생할 수 있다. 또한 락을 소유한 스레드가 락을 풀어놓지 않고 종료하거나 코딩이 잘못되어 무한 루프를 도는 경우, 스핀락이 열리기를 기다리는 다른 스레드들은 무한정 CPU를 사용하면서 영원히 기다리게 될 수도 있다.
```
현대 컴퓨터는 대부분 멀티 코어 CPU를 장착하고 있으므로 리눅스 커널은 스레드 동기화의 기본 기법으로 스핀락을 사용하고 있다.
```

## 뮤텍스와 스핀락의 차이
- 대기큐: 뮤텍스는 있음 / 스핀락은 없음
- 블록 가능 여부: 뮤텍스는 락이 잠겨 있으면 블록됨(blocking) / 스핀락은 락이 잠겨 있어도 블록되지 않고 계속 락 검사(non-blocking)
- lock/unlock 연산 비용: 뮤텍스는 저비용 / 스핀락은 CPU를 계속 사용하므로 고비용
- 하드웨어 관련: 뮤텍스는 단일 CPU에 적합 / 스핀락은 멀티코어 CPU에 적합
- 주 사용처: 뮤텍스는 사용자 모드, 사용자 응용 프로그램 / 스핀락은 커널 모드, 커널 코드, 인터럽트 서비스 루틴

## 세마포(Semaphore)
세마포는 n개의 자원을 다수의 스레드가 공유하여 사용하도록 돕는 자원 관리 기법이다.
- 자원: n개
- 대기 큐: 자원을 할당받지 못한 스레드가 잠자는 곳
- counter 변수: 사용가능한 자원의 개수를 나타내는 정수형 변수로 자원의 개수 n으로 초기화된다. counter 변수가 음수이면 자원을 기다리는 스레드의 개수를 나타낸다. counter 변수를 구현하는 방법에 따라 사용가능한 자원이 없을 때 counter 변수를 계속 0으로 유지하기도 한다.
- P/V 연산: P 연산은 자원 요청 시, V 연산은 자원 반환 시 실행되는 연산

스레드가 자원의 개수보다 작으면 아무 문제가 없지만, 자원의 개수보다 클 때 스레드들 사이에서 자원을 할당하고 해제하는 등 자원 관리가 필요하며 이때 세마포가 유용하다. 

뮤텍스나 스핀락은 여러 스레드가 임계구역을 진입하기 위해 경쟁할 때, 한 스레드에게 임계구역을 배타적으로 사용하도록 하는데 목적이 있지만, 세마포는 n개의 자원이 있고 여러 스레드들이 자원을 사용하고자 할 때 원활하게 관리하는 것이 목적이다.

### P 연산과 V 연산
P/V 연산은 wait/signal 연산으로도 불린다. P 연산은 스레드의 자원 사용을 허가하는 과정이다. P 연산은 counter 변수를 1 감소시키고, V 연산은 counter 변수를 1 증가시킨다. 세마포는 자원을 할당받지 못하는 스레드를 다루는 방법에 따라 다음 2가지 종류로 나뉘며 P/V 연산 역시 다르게 작동한다.
- sleep-wait 세마포
- busy-waiting 세마포

sleep-wait 세마포는 P 연산 중 자원 사용을 허가받지 못한 스레드는 가용 자원이 생길 때까지 대기 큐에서 잠을 자고(sleep-wait), V 연산에 의해 사용가능한 자원이 생기게 되면 깨어나 자원을 획득하는 형태이다.

busy-waiting 세마포는 P 연산에서 가용 자원이 생길 때까지 무한 루프를 돌면서 검사(busy-waiting)하는 방식이다. 그러다가 V 연산에 의해 가용 자원이 생기면, P 연산에서 자원을 획득하는 방식이다. busy-waiting 세마포에는 대기 큐가 필요 없다.

P/V 연산이 wait-signal 연산이라고 불리는 이유는, 자원을 사용하려는 스레드는 대기 큐에 있든 무한루프를 돌든 자원을 얻을 때까지 대기(wait)하고, 자원 사용을 끝낸 스레드는 대기하는 스레드에게 이를 알려(signal) 자원에 대한 스레드 동기화를 이루기 때문이다.

```
P/V 연산과 원자 명령
counter 변수는 P/V 연산에 의해 동시에 접근되므로 상호배제가 필요하다. 사실상 P/V 연산에서 counter 변수에 대한 접근 코드가 임계구역이 되며 원자명령으로 구현된다. counter 변수를 세마포 변수라고 부른다.
```

## 이진 세마포
세마포는 관리하는 자원이 여러 개인 경우와 1개인 경우에 따라 다음과 같이 구분된다.
- 카운터 세마포(counter semaphore) - 자원이 여러 개인 경우
- 이진 세마포(binary semaphore) - 자원이 1개인 경우

이진 세마포를 구성하는 요소는 다음과 같다.
- 세마포 변수 S - 0과 1 중 하나를 가지는 변수. 1로 초기화됨
- 대기 큐 - 자원이 사용가능하게 될 대까지 스레드들이 대기하는 큐
- P 연산 - 자원 사용의 허가를 얻는 과정으로 S를 1 감소시키고 0보다 작으면 스레드를 대기 큐에서 잠들게 한다. 만일 S가 0보다 크거나 같으면 스레드는 자원을 사용하는 코드를 실행한다.
- V 연산 - 자원 사용이 끝났음을 알리는 과정으로, S를 1 증가시키고 0보다 크면 그냥 리턴하고, 0보다 작거나 같으면 대기 큐에 있는 스레드 중 하나를 깨운다.

이진 세마포는 하나의 자원에 대해 여러 스레드가 사용하고자 할 때 관리하는 기법으로 뮤텍스와 매우 유사하다.

<hr>