# 운영체제

# 프로세스
## 프로그램과 프로세스 차이
프로그램(prgram)
- 하드디스크 등의 저장 매체에 저장
- 실행 파일의 형태

프로세스(prcess)
- 프로그램이 메모리에 적재되어 실행 중인 상태
  - 필요한 모든 자원을 할당 받는다.
  - 자원이란 코드/데이터/스택/힙 공간을 말한다.

## 프로세스 특징
- 운영체제는 프로그램을 메모리에 적재하고 프로세스로 다룬다.
- 운영체제는 프로세스에게 실행에 필요한 메모리를 할당한다. 이곳에 코드와 데이터 등을 적재한다.
- 프로세스들은 서로 독립적인 메모리 공간을 가진다. 다른 프로세스의 영역에 접근 불가능.

## 프로세스 관리
프로세스 생성에서 종료까지 관리는 모두 커널에 의해 이루어진다. 커널 영역에 프로세스 테이블을 만들고, 프로세스의 목록을 관리한다.

관리 내용
- 프로세스 생성/실행/일시중단/재개/중단
- 프로세스 정보 관리
  - 프로세스의 메모리 위치
  - 크기 
- 프로세스마다 고유한 번호(프로세스 ID)를 할당
- 프로세스 통신
- 프로세스 동기화
- 프로세스 컨텍스트 스위칭

## 프로그램의 다중 인스턴스
한 프로그램을 여러 번 실행시켜 다중 인스턴스를 생성할 수 있다. 운영체제는 프로그램을 실행할 때마다 독립된 프로세스를 생성한다. 각 프로세스는 독립된 메모리 공간이 할당된다. 

## 프로세스를 구성한 4개의 메모리 영역
### 코드(code) 영역
실행될 프로그램 코드가 적재되는 영역
- 사용자가 작성한 모든 함수 코드
- 사용자가 호출한 라이브러리 함수 코드

### 데이터(data) 영역
프로그램에서 고정적으로 만든 변수 공간으로 프로세스 적재 시 할당, 종료 시 소멸된다.
- 전역 변수 공간
- 정적 데이터 공간
- (사용자 프로그램과 라이브러리 포함)

### 힙(heap) 영역
프로세스가 실행 도중 동적으로 사용할 수 있도록 할당된 공간
- malloc() 등으로 할당받은 공간
  
힙 영역에서 아래 번지로 내려가며 할당된다.

### 스택(stack) 영역
함수가 실행될 때 사용될 데이터를 위해 할당된 공간
- 매개변수
- 지역변수
- 리턴값

함수는 호출될 때, 스택 영역에서 위쪽으로 공간을 할당한다. 함수가 return 하면 할당된 공간이 반환된다. 함수 호출 외에 프로세스에서 필요 시 사용가능하다.

## 프로세스 주소 공간
프로세스가 실행 중에 접근할 수 있도록 허용된 주소의 최대 범위이다. 

프로세스 주소 공간은 논리 공간(가상 공간)이다. 0번지에서 시작하여 연속적인 주소를 갖는다.

프로세스 주소 공간은 CPU가 액세스할 수 있는 전체 크기이다. (32 비트 CPU의 경우, 4GB)

### 프로세스 공간과 프로세스 현재 크기
프로세스 주소 공간의 크기는 프로세스의 현재 크기와 다르다.
- 프로세스 주소 공간 크기: 프로세스가 액세스할 수 있는 최대 크기
- 프로세스 현재 크기: 적재된 코드 + 전역 변수 + 힙 영역에서 할당받아 사용중인 동적 메모리 공간 + 현재 스택 영역에 저장된 데이터 크기

### 사용자 공간과 커널 공간
프로세스 주소 공간은 2부분으로 나뉘어진다.

사용자 공간
- 프로세스의 코드, 데이터, 힙, 스택 영역이 할당되는 공간
- 코드와 데이터 영역의 크기는 프로세스 시작 시 결정된다.
- 힙과 스택의 영역 크기는 정해져 있지 않다.
- 힙 영역은 아래로 자라고, 스택은 위로 자란다.
  
커널 공간
- 프로세스가 시스템 호출을 통해 이용하는 커널 공간
- 커널 코드, 커널 데이터, 커널 스택(커널이 실행될 때)
- 커널 공간은 모든 사용자 프로세스에 의해 공유된다.
  
### 가상 공간
프로세스 주소 공간은 사용자나 개발자가 보는 관점이다.
- 자신이 작성한 프로그램이 0번지부터 시작하여
- 연속적인 메모리 공간에 형성되고,
- CPU가 액세스할 수 있는 최대 크기의 메모리가 설치되어 있다고 상상

실제 상황
- 실제 물리 메모리 크기는 프로세스 주소 공간보다 작을 수 있다.
- 프로세스의 코드, 데이터, 힙, 스택 영역은 물리 메모리에 흩어져 저장된다. 연속적인 메모리 공간이 아니다.

# 커널의 프로세스 관리
## 프로세스 테이블과 프로세스 제어 블록
프로세스 테이블(Process Table) : 시스템의 모든 프로세스들을 관리하기 위한 표
- 시스템에 1개만 존재한다.
- 구현 방식은 OS마다 다르다.

프로세스 제어 블록(Process Control Block, PCB) : 프로세스에 관한 정보를 저장하는 구조체
- 프로세스당 1개씩 존재
- 프로세스가 생성될 때 만들어지고 종료되면 삭제된다.
- 커널에 의해 생성되고 저장, 읽혀지는 등 관리된다.

프로세스 테이블과 프로세스 제어 블록의 위치
- 커널 영역, 커널 코드(커널 모드)만이 액세스 가능

# 프로세스 생명 주기와 상태 변이(state change)
## 프로세스의 생명 주기
프로세스는 탄생에서 종료까지 여러 상태로 바뀌면서 실행된다.

<img src="../imgs/os-state-change.png">

## 프로세스의 상태
### New [생성 상태]
- 프로세스가 생성된 상태
- 메모리 할당 및 필요한 자원을 적재한다.

### Ready [준비 상태]
- 프로세스가 스케줄링을 기다리는 준비 상태
- 프로세스는 준비 큐에서 대기한다.
- [dispatch] 스케줄링되면 Running 상태로 바뀌고 CPU에 의해 실행된다.

### Running [실행 상태]
- 프로세스가 CPU에 의해 현재 실행되고 있는 상태
- [timeout] CPU의 시간할당량(타임슬라이스,time slice)가 지나면 다시 Ready 상태로 바뀌고 준비 큐에 삽입된다.
- [block] 프로세스가 입출력을 시행하면 커널은 프로세스를 Blocked 상태로 만들고 대기 큐에 삽입한다.

### Blocked/Wait [블록 상태]
- 프로세스가 자원을 요청하거나, 입출력 요청하고(시스템 호출) 완료를 기다리는 상태
- [wakeup] 입출력이 완료되면 프로세스는 Ready 상태로 바뀌고 준비 큐에 삽입된다.

### Terminated/Zombie 상태
- 프로세스가 종료된 상태
- 프로세스가 차지하고 있던 메모리와 할당받았던 자원을 모두 반환(열어 놓은 파일 닫힘)
- Zombie 상태: 프로세스의 PCB에 남긴 종료코드를 부모 프로세스가 읽어가지 않아 완전히 종료되지 않은 상태
  - 프로세스의 테이블 항목과 PCB가 시스템에 여전히 남아있는 상태

### Terminated/Out 상태
- 프로세스가 종료하면서 남긴 종료코드를 부모 프로세스가 읽어가서 완전히 종료된 상태
- 프로세스 테이블의 항목과 PCB가 시스템에서 완전히 제거된 상태

## 프로세스 스케줄링과 컨텍스트 스위칭 
과거 OS의 실행단위는 프로세스였다. Ready 상태의 프로세스 중 실행 시킬 프로세스를 선택했다.

오늘날 OS의 실행단위는 스레드다. Ready 상태의 스레드 중 실행 시킬 스레드를 선택한다.

프로세스는 스레드들에게 공유 자원을 제공하는 컨테이너(Container)로 역할이 바뀌었다. 

# Process vs Thread
<img src="../imgs/os-thread.png">

Process
- 실행 중인 프로그램으로, 디스크로부터 메모리에 적재되어 운영체제로부터 주소 공간, 파일, 메모리 등을 할당 받음
- 함수의 매개변수, 복귀 주소, 로컬 변수와 같은 임시 자료를 저장하는 프로세스 스택과 전역 변수들을 저장하는 데이터 섹션, 프로세스 실행 중에 동적으로 할당받는 메모리 힙을 포함
- 특정 프로세스에 대한 중요한 정보를 저장하고 있는 운영체제의 자료구조를 PCB(Process Control Block)라고 하며, 운영체제는 프로세스 생성과 동시에 고유한 PCB를 생성하여 프로세스를 관리

Thread
- 프로세스의 실행 단위. 한 프로세스 내에서 동작되는 여러 실행 흐름으로 프로세스 내의 Heap, Data, Code 영역을 공유
- 각각의 스레드는 독립적인 작업을 수행해야 하기 때문에 각자의 스택과 PC Register 값을 가지고 있음

```
스택을 스레드마다 독립적으로 할당하는 이유

- 스택은 함수 호출 시 전달되는 인자, 되돌아 갈 주소값 및 함수 내에서 선언하는 변수 등을 저장하기 위해 사용되는 메모리 공간이다. 

- 스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능하다는 것이다. 스레드의 정의에 따라 독립적인 실행 흐름을 가지기 위한 최소 조건으로 독립된 스택을 할당한다.
```

<hr>

출처
- [프로세스와 스레드 : Process vs. Thread](https://eun-jeong.tistory.com/19)

<hr>

# 인터럽트 
## 인터럽트란
프로세서가 현재 실행을 일시 중단하고 발생한 인터럽트를 서비스하도록 요청하는 신호이다. 인터럽트를 서비스하기 위해, 프로세서는 대응하는 인터럽트 서비스 루틴(ISR)을 실행한다. 인터럽트 서비스 루틴의 실행 후에, 프로세서는 정지된 프로그램의 실행을 재개한다. 

## 인터럽트가 필요한 이유
### 선점형 스케줄러 구현
프로세스를 교체하기 위해 스케줄러가 Running 상태인 프로세스를 중지시켜야 함

### IO Device와의 상호작용
저장 매체에서 데이터 처리 완료 시, 프로세스를 깨워야 함 (wakeup)

### 예외 상황 핸들링 
CPU가 프로그램을 실행하고 있을 때, 입출력 하드웨어 등의 장치나 예외상황이 발생할 경우, CPU가 해당 처리를 할 수 있도록 CPU에게 알려야 함

## 인터럽트 종류
### 하드웨어 인터럽트
장치들이 CPU에게 어떤 상황 발생을 알리는 하드웨어 신호다. 인터럽트가 발생하면 CPU는 인터럽트 서비스 루틴을 실행한다.
- I/O interrupt
- timer interrupt
- Maskable interrupt: 프로세서가 더 높은 우선순위로 프로그램을 실행할 경우 무시되거나 지연될 수 있다.
- Non Maskable interrupt: 무시되거나 지연될 수 없으며 프로세서에 의해 즉시 서비스되어야 한다.

### 소프트웨어 인터럽트
소프트웨어 인터럽트는 조건이 충족되거나 시스템 호출이 발생할 때 발생하는 인터럽트다. 어떤 경우에는 소프트웨어 인터럽트가 설계상이 아닌 프로그램 실행 오류에 의해 예기치 않게 발생할 수 있다. 이러한 인터럽트를 exceptions 또는 traps라고 한다. 

## 인터럽트 발생 처리 과정
<img src="../imgs/Instruction-Cycle-with-Interrupts.jpg">

일반적인 명령 주기는 명령 가져오기 및 실행으로 시작합니다. 그러나, 명령어의 정상적인 처리 중에 인터럽트가 발생하는 것을 수용하기 위해, 그림과 같이 인터럽트 사이클을 정상적인 명령 사이클에 추가한다.

현재 명령이 실행된 후, 프로세서는 인터럽트 신호를 확인하여 보류 중인 인터럽트가 있는지 확인합니다. 보류 중인 인터럽트가 없으면 프로세서는 시퀀스의 다음 명령을 가져오기 위해 계속한다. 

프로세서가 보류 중인 인터럽트를 발견하면, 실행되어야 하는 다음 명령어의 주소를 저장함으로써 현재 프로그램의 실행을 중단하고 프로그램 카운터(PC)를 인터럽트 서비스 루틴의 시작 주소로 업데이트하여 발생한 인터럽트를 서비스한다. 인터럽트가 완전히 서비스된 후 프로세서는 중단된 프로그램의 실행을 다시 시작합니다.

### 인터럽트 신호 허용
IE 플래그가 1로 설정되면 프로세서는 발생한 인터럽트를 허용합니다. IE 플래그가 0으로 설정된 경우 요청된 인터럽트를 무시합니다.

## 인터럽트 vs 폴링
폴링은 컴퓨터 시스템의 마이크로 컨트롤러가 모든 장치의 상태를 지속적으로 확인하는 지속적인 모니터링 상태이다. 마이크로 컨트롤러가 폴링을 하는 동안 다른 작업을 수행할 수 없기 때문에 낭비가 크다. 인터럽트를 사용하면 컨트롤러가 장치의 상태를 정기적으로 모니터링 할 필요가 없다. 인터럽트가 발생할 때만 응답하면 된다. 

<hr>

출처
- [Interrupts in Computer Architecture](https://binaryterms.com/interrupts-in-computer-architecture.html)
- [interrupt](https://www.techtarget.com/whatis/definition/interrupt)
- [인터럽트(Interrupt)란?](https://whatisthenext.tistory.com/147)

<hr>

# 캐시의 지역성(Locality)
## 캐시 메모리란
캐싱(caching)은 컴퓨터의 처리 성능을 높이기 위한 기법이다. CPU는 데이터를 처리하기 위해 메모리에 끊임없이 액세스 하는데, CPU에 비해 메모리 속도가 느려 CPU가 효율적으로 사용되지 못한다. 이를 해결하기 위해 CPU와 메모리 사이에 캐시를 두어 CPU의 메모리 액세스 횟수를 줄인다.

## 캐시 적중과 실패
캐시 메모리가 있는 컴퓨터 시스템은 CPU는 메모리에 접근하기 전에 캐시 메모리를 먼저 확인한다. 이때 필요한 데이터가 있는 경우 <strong>적중(hit)</strong>, 없는 경우를 <strong>실패(miss)</strong>라고 한다.

캐시에 저장할 데이터는 지역성을 가져야하는데 지역성이란 데이터 접근이 시간적 혹은 공간적으로 가깝게 일어나는 것을 말한다.

요청한 데이터를 캐시 메모리에서 찾을 확률을 <strong>적중률(hit ratio)</strong>라고 한다. 

캐시 메모리의 성능은 적중률에 의해 결정된다.
```
         캐시 메모리의 적중 횟수
적중률 = -----------------------
         전체 메모리의 참조 횟수
```

캐시 메모리의 적중 여부는 <strong>참조의 지역성(Locality of reference)</strong> 원리에 달려있다. 지역성이란 기억장치 내의 정보를 균일하게 접근하는 것이 아닌 어느 한 순간에 특성 부분을 집중적으로 참조하는 특성이다.

## 지역성의 종류
### 시간적 지역성(Temporal Locality)
특정 데이터가 한번 접근되었을 경우, 가까운 미래에 또 한번 데이터에 접근할 가능성이 높은 것.

메모리 상의 같은 주소에 여러 차례 읽기 쓰기를 수행할 경우, 상대적으로 작은 크기의 캐시를 사용해 효율성을 높일 수 있다.


### 공간적 지역성(Spatial Locality)
특정 데이터와 가까운 주소가 순서대로 접근되었을 경우.

CPU 캐시나 디스크 캐시의 경우 한 메모리 주소에 접근할 때 그 주소 뿐 아니라 해당 블록을 전부 캐시에 가져오게 된다. 이때 메모리 주소를 오름차순이나 내림차순으로 접근하면 캐시에 이미 저장된 같은 블록의 데이터를 접근하게 되므로 캐시 효율성이 향상된다.

### 순차적 지역성(Sequential Locality)
분기가 발생하지 않는 한 명령어는 메모리에 저장된 순서대로 인출/실행된다.

<hr>

출처
- [캐시 메모리(cache memory)의 개요 정리](https://zion830.tistory.com/46)
- [Caching Locality와 Cache Hit Ratio에 대해 설명하시오](https://github.com/lunchScreen/Interview_Questions/issues/98)

<hr>

# 뮤텍스와 세마포어 차이
## 임계영역과 상호배제
```
임계영역(Critical Section): 여러 프로세스가 데이터를 공유하며 수행될 때, 각 프로세스에서 공유 데이터를 접근하는 프로그램 코드 블록
```
```
상호 배제(Mutual Exclution): 임계 구역을 어느 시점에서 단지 한 개의 프로세스만이 사용할 수 있도록 하며, 다른 프로세스가 현재 사용 중인 임계 구역에 대하여 접근하려고 할 때 이를 금지하는 행위
```

프로세스 간 메시지를 전송하거나, 공유메모리를 통해 공유된 자원에 여러 개의 프로세스가 동시에 접근하면 임계영역 문제가 발생할 수 있다. 이를 해결하기 위해 <strong>데이터를 한 번에 하나의 프로세스만 접근할 수 있도록 제한을 두는 동기화 방식</strong>을 취해야 한다. 

동기화 도구에는 대표적으로 뮤텍스(Mutex)와 세마포어(Semaphore)가 있다. 이들은 모두 공유된 자원의 데이터를 여러 스레드/프로세스가 접근하는 것을 막는 역할을 한다.

## 뮤텍스 (Mutex)
공유된 자원의 데이터 혹은 임계영역(Critical Section) 등에 <strong>하나의 Process 혹은 Thread</strong>가 접근하는 것을 막아준다. 

-> 즉, 동기화 대상이 하나

임계영역(Critical Section)을 가진 스레드들의 실행시간(Running Time)이 서로 겹치치 않고 각각 단독으로 실행(상호배제)되도록 하는 기술이다. 

<img src="../imgs/os-mutex.png">

한 프로세스에 의해 소유될 수 있는 <strong>key를 기반으로 한 상호배제 기법</strong>이다. key에 해당하는 어떤 객체(object)가 있으며, <strong>이 객체를 소유한 스레드/프로세스만이 공유자원에 접근</strong>할 수 있다. 

다중 프로세스들의 공유 자원에 대한 접근을 조율하기 위해 <strong>동기화(Synchronization) 또는 락(Lock)</strong>을 사용함으로써 <strong>뮤텍스 객체를 두 스레드가 동시에 사용할 수 없다.</strong>

## 세마포어 (Semaphore)
공유된 자원의 데이터 혹은 임계영역(Critical Section) 등에 <strong>여러 Process 혹은 Thread</strong>가 접근하는 것을 막아준다. 

-> 즉, 동기화 대상이 하나 이상

<img src="../imgs/os-semaphore.png">

사용하고 있는 스레드/프로세스의 수를 <strong>공통으로 관리하는 하나의 값</strong>을 이용해 상호배제를 달성한다. 공유자원에 접근할 수 있는 <strong>프로세스의 최대 허용치만큼 동시에 사용자가 접근</strong>할 수 있으며, <strong>각 프로세스는 세마포어의 값을 확인하고 변경</strong>할 수 있다. 

자원을 사용하지 않는 상태가 될 때, 대기하던 프로세스가 즉시 자원을 사용한다. 이미 다른 프로세스에 의해 사용 중이라는 사실을 알게 되면, 재시도 전에 일정시간 대기해야 한다.

## 차이점
가장 큰 차이점은 <strong>동기화 대상의 개수</strong>이다.

Mutex
- 동기화 대상이 오직 1개일 때 사용한다.
- 자원을 소유하고 책임을 갖는다.
- 상태가 0, 1 뿐이므로 Lock을 가질 수 있고, 소유하고 있는 스레드만이 Mutex를 해제할 수 있다.
- 프로세스의 범위를 가지며 프로세스 종료될 때 자동으로 Clean up 된다.

Semaphore
- 동기화 대상이 1개 이상일 때 사용한다.
- 자원 소유가 불가하다.
- Semaphore를 소유하지 않는 스레드가 Semaphore를 해제할 수 있다.
- 시스템 범위에 걸쳐 있고, 파일 시스템 상의 파일로 존재한다.


## 결론
뮤텍스와 세마포어 모두 완벽한 기법은 아니므로, 데이터 무결성을 보장할 수 없고 모든 교착상태를 해결하지 못한다. 하지만 상호배제를 위한 기본적인 문법이며 여기에 좀 더 복잡한 매커니즘을 적용해 개선된 성능을 가질 수 있도록 하는 것이 중요하다.

<hr>

출처
- [Mutex 뮤텍스와 Semaphore 세마포어의 차이](https://heeonii.tistory.com/14)

<hr>

# 동기(Sync)와 비동기(Async) 차이
## 동기(Synchronous: 동시에 일어나는)
- 단일 스레드 모델
- 작업이 하나씩 순서대로 수행된다.
- 첫번째 작업이 완료되야지 다음 작업이 수행된다. 
- 블로킹 아키텍처로 반응성 시스템 프로그래밍에 적합하다.
- ex) 전화 

## 비동기(Asynchronous : 동시에 일어나지 않는)
- 멀티 스레드 모델
- 하나 이상의 작업이 진행되는 동안 추가적인 작업을 차단하지 않는다.
- 다른 작업이 완료될 때까지 기다리지 않고 여러 관련 작업을 동시에 실행할 수 있다.
- 함수가 호출될 때부터 함수의 값이 반환될 때까지의 지연 시간을 줄인다. 
  - 사용자는 자신의 앱이 빠르게 실행되기를 원하지만, API에서 데이터를 가져오는 데는 시간이 걸린다. 이러한 경우 비동기식 프로그래밍은 앱 화면이 더 빨리 로드되도록 도와주어 사용자 경험을 향상시킨다. 
- 논블로킹 아키텍처로 네트워킹 및 통신 프로그래밍에 적합하다.
- ex) 문자 메시지


## 차이점
Sync
- 단일 스레드로 한 번에 하나의 작업/프로그램만 실행된다.
- 서버에 한 번에 하나의 요청만 보내고, 해당 요청이 서버에 의해 응답될 때까지 기다린다.
- 속도가 느리지만 체계적이다.

Async
- 멀티 스레드로 여러 작업이나 프로그램이 병렬로 실행된다.
- 서버에 여러 요청을 전송한다.
- 여러 작업을 동시에 실행할 수 있어 처리량이 증가한다.

<hr>

출처
- [Asynchronous vs. Synchronous Programming](https://www.mendix.com/blog/asynchronous-vs-synchronous-programming/)

<hr>

# 멀티 스레드 프로그래밍
## 멀티 스레딩(Multi-threading)이란?
<img src="../imgs/os-multithreadingprogramming.jpg">

- 하나의 프로세스를 다수의 실행 단위로 구분하여 자원을 공유하고 자원의 생성과 관리의 중복성을 최소화하여 수행 능력을 향상 시키는 것
- 하나의 프로그램에서 동시에 여러 개의 일을 수행할 수 있도록 해줌(사실 분산처리를 통해 동시에 실행되는 것 처럼 보이는 것)
  - ex) 워드 프로세서에서 그림을 표시하고, 키 입력에 응답하며 철자 및 문법 검사를 계속 함
  
    <img src="../imgs/os-multithreading.jpg">

## 장점
### 1. 응답성
프로그램의 일부분(스레드)이 중단되거나 긴 작업을 수행하더라도, 프로그램의 수행이 계속 되어 사용자에 대한 응답성이 증가한다.

ex) 멀티 스레드가 적용된 웹 브라우저 프로그램에서 하나의 스레드가 이미지 파일을 로드하고 있는 동안, 다른 스레드에서 사용자와 상호작용 가능

### 2. 경제성
프로세스 내 자원들과 메모리를 공유하기 때문에 메모리 공간과 시스템 자원소모가 줄어든다. 스레드 간 통신이 필요한 경우에도 쉽게 데이터를 주고 받을 수 있으며, 프로세스의 context switching과 달리 스레드 간 context switching은 캐시 메모리를 비울 필요가 없기 때문에 더 빠르다.

### 3. 멀티프로세서 활용
다중 CPU 구조에서는 각각의 스레드가 다른 프로세서에서 병렬로 수행될 수 있으므로 병렬성이 증가한다.

## 단점
### 1. 임계 영역
공유하는 자원에 동시 접근하는 경우, 프로세스와 달리 스레드는 데이터와 힙 영역을 공유하기 때문에 어떤 스레드가 다른 스레드에서 사용 중인 변수나 자료구조에 접근하여 엉뚱한 값을 읽어오거나 수정할 수 있다. 따라서 동기화가 필요하다.

### 2. 동기화
동기화를 통해 스레드의 작업 처리 순서와 공유 자원에 대한 접근을 컨트롤 할 수 있다. 그러나 불필요한 부분까지 동기화 하는 경우, 과도한 lock으로 인해 병목 현상을 발생시켜 성능이 저하될 가능성이 높기 때문에 주의해야 한다.
동기화 방법에는 뮤텍스와 세마포어가 있다.

### 3. context switching
동기화 등의 이유로 싱글 코어 멀티 스레딩은 스레드 생성 시간이 오히려 오버헤드로 작용해 단일 스레드보다 느리다. 

<hr>

출처
- [멀티스레드 : Multi-thread (장단점, 멀티프로세스와 차이)](https://eun-jeong.tistory.com/20)

<hr>

# 메모리 단편화 해결
## 메모리 관리 문제
### 배경 키워드
프로세스
- 독립된 메모리 공간을 갖는다
- 독립된 메모리이기 때문에 다른 프로세스의 메모리 공간에 일반적으로 접근할 수 없다.

운영체제
- 메모리의 커널 공간과 사용자 공간의 접근에 제약 받지 않는다.

Swapping
- 메모리 관리를 위해 사용되는 기법이다.
  - 예를 들어 CPU 할당 시간이 끝난 프로세스의 메모리를 HDD 같은 보조 기억장치로 내보내고 다른 프로세스의 메모리를 불러 들일 수 있다.

Swap-in
- 주 기억장치(RAM)로 불러오는 과정

Swap-out
- 보조 기억장치로 내보내는 과정
  
단편화(Fragmentation)
- 메모리 적재&제거가 반복되면서 프로세스들이 차지하는 메모리 틈 사이에 사용하지 못할 만큼의 작은 자유 공간들을 의미한다.
- '외부 단편화'와 '내부 단편화' 두 가지 종류로 나뉜다.

### 외부 단편화
물리 메모리(RAM)에서 할당할 수 없는 작은 공간들이 생기는 것을 말한다.

```
RAM 외부 단편화
|   프로세스A   |free|  프로세스B  |free| 프로세스C |free|    	프로세스D    |
```
free를 하나로 모으면 다른 프로세스를 할당할 수 있지만, 각각 분산되어 있어 프로세스를 불러올 수 없다. 이 분산된 상태를 외부 단편화라 한다.

-> 압축을 통해 해결하기도 한다.

압축이란 프로세스 사용 공간을 한쪽으로 몰아 자유공간을 확보하는 것이다. 하지만 작업 효율이 좋지 않다.

### 내부 단편화
프로세스가 사용하는 메모리 공간 안에 남는 부분을 말한다.
```
프로세스 A의 내부 공간
|       9,999B       |2B|
```
프로세스 내 메모리 공간이 10,000B일 때, 그 안에서 9,999B 사용하면 2B라는 메모리가 남게되고, 이 현상을 내부 단편화라 한다.

## 매모리 단편화 해결 방법
### 1. 페이징 (Paging) - 가상 메모리 사용, 외부 단편화 해결 
프로세스를 일정 크기로 잘게 쪼개어 순서와 상관없이 적재하는 방식이다. 

<img src="../imgs/os-paging.png">

물리 메모리(Frame)안에 프로세스의 논리 메모리(Page)들이 고정된 크기의 블록으로 적재된다. ( => 프로세스를 일정한 크기인 Page로 잘라서 메모리에 적재하는 방식)

배치 순서는 상관없기 때문에 메모리 공간을 연속된 순서로 차지하지 않아 외부 단편화 문제를 해결한다.

단점은 내부 단편화 문제의 비중이 늘어난다.

### 2. 세그먼테이션 (Segmentation) - 가상 메모리 사용, 내부 단편화 해결
페이징과 다르게 고정된 크기가 아닌 서로 다른 크기의 논리적인 단위인 세그먼트로 분할하는 방식이다.

<img src="../imgs/os-segment.png">

page 처럼 크기가 동일하지 않기 때문에 세그먼트 번호와 시작 주소(base), 세그먼트 크기(limit)를 갖는다.

단점은 서로 다른 크기의 세그먼트들이 메모리에 적재되고 제거되는 일이 반복되다 보면, 작은 조각의 자유 공간들이 많아지면서 외부 단편화 문제가 발생한다.

### 3. 메모리 풀 (Memory Pool) - 내부 단편화, 외부 단편화 해결
고정된 크기의 블록을 할당하여 메모리 동적 할당을 가능하게 해준다. memory pool이라 불리는 동일한 사이즈의 메모리 블록들을 미리 할당해 놓고 프로세스들이 필요할 때마다 사용하고 반납하는 기법이다. (=> 미리 할당하기 때문에 메모리 누수가 있다.)

미리 공간을 할당해놓고 사용한 다음 반납하기 때문에 이로 인한 외부 단편화 문제는 발생하지 않는다. 또한 필요한 크기만큼 할당하기 때문에 내부 단편화도 존재하지 않는다.

메모리의 할당, 해제가 빈번할 때는 메모리 풀 방식이 효과적이다.

### 4. 압축(Compaction)
메모리 공간들을 재배치 하여, 단편화로 인해 분산되어 있는 메모리 공간들을 하나로 합치는 기법이다.

```
|프로세스|  free  |프로세스|프로세스|프로세스| free | 
⬇️
|프로세스|프로세스|프로세스|프로세스|   free   |    
```

### 5. 통합(Coalescing)
단편화로 인해 분산된 메모리공간들을 인접해 있는 것끼리 통합시켜 큰 메모리 공간으로 합치는 기법이다. 압축은 재배치가 일어나지만 통합은 인접한 공간들끼리 통합된다는 차이가 있다.

```
|프로세스|프로세스|프로세스|프로세스|   free   |    
⬇️
|프로세스|프로세스|프로세스|  free  |   free   |    
⬇️
|프로세스|프로세스|프로세스|     free     |    
```

<hr>

출처
- [메모리 단편화를 해결하는 세 가지 방법](https://daco2020.tistory.com/174)
- [메모리 압축(compaction)과 메모리 통합(coalescing)](https://m.blog.naver.com/qbxlvnf11/221367174686)

<hr>

# 가상 메모리 
가상 메모리는 메모리 관리 기법 중 하나로, 기계에 실제로 이용 가능한 자원을 추상화하여 사용자들에게 매우 큰 메모리인 것 처럼 보이게 만든다. 즉, 프로그램에 실제 메모리 주소가 아닌 가상 메모리 주소를 주는 방식이다.

<img src="../imgs/os-demandpaging.png">

- 논리 주소(가상 주소): 가상적으로 주어진 주소
- 물리 주소: 실제 메모리 상에서 유효한 주소

논리 주소는 <strong>주소 변환을 담당하는 하드웨어인 MMU</strong>(메모리 관리 장치: Memory Management Unit)에 의해 물리 주소로 변환된다.

### 가상 메모리 장점 
- 사용자 프로그램이 물리 메모리보다 커져도 된다. 즉, 물리적 메모리의 제약을 벗어나게 해준다.
- 시스템이 더 많은 프로세스를 수용할 수 있게 해준다.
- CPU 이용률과 처리율이 높아진다.
- 프로그램을 메모리에 올리고 스왑 하는 필요한 입출력 횟수가 줄어든다.

## 요구 페이징
요구 페이징은 프로그램 실행 시 프로세스를 구성하는 모든 페이지를 한꺼번에 메모리에 올리는 것이 아니라, 당장 사용될 페이지만을 올리는 방식이다. 따라서 요구 페이징 기법에서는 특정 페이지에 대해 CPU의 요청이 들어온 뒤 해당 페이지를 메모리에 적재한다.

## 페이지 부재 (Page Fault)
가상 메모리 기법(요구 페이징)은 일부 페이지만 메모리에 적재되어 있고 나머지는 디스크의 swap 영역에 존재한다. 이러한 이유로 메모리에 페이지가 존재하는지 구별하기 위해 valid-invalid bit를 두어 각 페이지가 존재하는지 표시한다.

이때, <strong>페이지가 메모리에 적재되지 않아</strong> valid-invalid bit에 invalid로 세팅되어 있는 경우를 <strong>페이지 폴트</strong>가 일어났다고 한다. 

### 페이지 부재 (Page Fault) 처리 과정

<img src="../imgs/os-pagefault.png">

CPU가 invalid 페이지에 접근하면 주소 변환을 담당하는 하드웨어인 MMU(Memory Management Unit)가 페이지 부재 트랩(Page Fault Trap)을 발생시킨다. (=> 인터럽트 발생)

다음으로 CPU의 제어권이 커널모드로 변경되고, 운영체제의 페이지 폴트 인터럽트 서비스 루틴이 호출된다.

1. 운영체제가 해당 페이지에 접근하기 위해 주소가 유효한지 확인한다.
2. 범위가 벗어나는 영역에 속한 페이지 접근이나 접근 권한을 위반할 경우 프로세스를 종료시킨다.
3. 접근이 가능한 경우 물리 메모리에 비어있는 프레임을 할당받는다.
4. 비어 있는 프레임이 없다면 기존에 메모리에 올라와 있는 페이지 중 하나를 디스크로 보낸다.(swap-out)
5. 디스크로부터 메모리 적재는 오랜 시간이 걸린다. 따라서 페이지 폴트가 발생한 프로세스는 CPU를 반납하고 PCB에 현재 상태를 저장한 후 block 상태가 된다.
6. 디스크 입출력이 완료되어 인터럽트가 발생되면, 해당 페이지의 valid-invalid bit를 valid로 수정한다.
7. block 된 프로세스를 준비 큐로 이동시킨다.
8. CPU를 할당받고 PCB로부터 저장된 값을 복원시켜 중단되었던 명령부터 실행을 이어간다.

<hr>

출처
- [요구 페이징(가상메모리)](https://zangzangs.tistory.com/142)
- [가상메모리(Virtual Memory)와 요구 페이징(Demand Paging), Valid-Invalid Bit, 페이지 부재(Page Fault)과정](https://code-lab1.tistory.com/59)

<hr>

# 임계구역과 상호배제
스레드 동기화는 공유 데이터를 사용하려고 다수의 스레드가 경쟁하는 경우, 먼저 접근한 스레드가 공유 데이터를 배타적으로 사용하도록 다른 스레드가 접근하지 못하게 상호 협력(coordination)하는 것이다. 여기서, 스레드 동기화와 관련하여 반드시 알아야 할 중요한 다음 2개의 용어가 있다.
```
임계 구역과 상호배제
```
<strong>사용자가 작성한 프로그램 중 공유 데이터에 접근하는 일부의 코드들</strong>을 임계구역(critical section)이라고 부른다. 그리고 <strong>다수의 스레드로부터 공유 데이터의 훼손을 막기 위해 임계구역은 반드시 한 스레드만 배타적 독점적으로 실행하도록 관리</strong>되어야 한다. 이를 상호배제(mutual exclusion)라고 부른다. 상호배제의 핵심은 임계구역에 먼저 진입한 스레드가 임계구역의 실행을 끝낼 때까지 다른 스레드가 진입하지 못하도록 보장하는 것이다. 상호배제의 장치가 없는 임계구역은 있을 수 없다. 임계구역 설정은 멀티스레드 응용프로그램 개발자의 판단에 따라 이루어진다. 개발자 스스로 공유 데이터를 액세스하는 코드 블록을 임계구역으로 묶고, 임계구역에 대한 상호배제가 이루어지도록 작성해야 한다. 이러한 작업들은 일반적으로 멀티스레드 라이브러리나 시스템 호출을 이용하여 작성한다.
```
thread-safe와 thread-unsafe
공유 데이터가 여러 스레드에 의한 동시 접근에도 훼손되지 않게 유지될 때 'thread-safe'라고 한다. 공유 데이터에 대한 스레드의 동기화가 잘 구현되어 있다는 뜻이다. 예를 들어 자바에서 Vector 클래스는 thread-safe하다. 여러 자바 스레드들이 하나의 Vector 객체를 동시에 사용해도 스레드 동기화가 이루어지도록 Vector 클래스가 작성되어 있다는 뜻이다. 반면 자바의 ArrayList 클래스는 thread-unsafe하여 멀티 스레드에 의해 사용되면 문제가 발생할 수 있다. 한편, ArrayList는 데이터를 넣고 뺄 때마다 동기화 기능을 수행하는 긴 코드를 가진 Vector보다 속도가 빨라 단일 스레드 응용 프로그램에게는 유리하다.
```

## 임계구역 문제
### 해결 조건
임계 구역 문제를 해결하기 위해서는 다음 3가지 조건을 충족해야 한다.
1. 상호배제(mutual exclusion)
   - 하나의 프로세스가 임계 구역에 들어가 있다면 다른 프로세스는 들어갈 수 없어야 한다.
2. 진행(progress)
   - 임계 구역에 들어간 프로세스가 없는 상태에서, 들어가려고 하는 프로세스가 여러 개 있다면 어느 것이 들어갈지를 적절히 결정해주어야 한다.
3. 한정 대기(bounded waiting)
   - 다른 프로세스의 기아(Starvation)를 방지하기 위해, 한 번 임계 구역에 들어간 프로세스는 다음 번 임계 구역에 들어갈 때 제한을 두어야 한다.

### 해결 방법
- 소프트웨어적 방법 - Peterson's 알고리즘 등
- 하드웨어적 방법 - 인터럽트 서비스 금지, 원자 명령 활용

소프트웨어적 방법과 하드웨어적 방법으로 나눌 수 있다. 소프트웨어적인 방법(Peterson's 알고리즘 등)은 알고리즘 수준에서 제시된 것들로 실제 구현에 있어 여러 문제를 노출하기 때문에, 오늘 날에는 하드웨어적 방법(원자명령)을 사용한다. 임계구역의 상호배제는 '임계구역의 진입코드(entry 코드)와 진출코드(exit 코드)'를 어떻게 구현하느냐가 관건이다.

## 상호배제 구현 방법 - 원자명령(atomic instruction)
원자명령이란 두 명령 사이에 컨텍스트 스위칭이 일어나지 않도록 두 명령을 하나의 명령으로 만드는 것이다. 원자명령은 TSL(Test and Set Lock)라고도 부른다. 개발자는 다양한 동기화 라이브러리를 통해 구현할 수 있다. 

```
모든 CPU 명령은 원자적인데 TSL을 특별히 원자명령이라고 부르는 이유
모든 기계 명령은 원자적이어서 CPU가 기계 명령을 실행하는 도중 중단하는 일은 없다. CPU는 명령을 실행 중일 때 인터럽트가 발생한다고 하더라도, 현재 실행 중인 기계 명령을 실행한 후 인터럽트를 서비스한다. 하나의 기계 명령을 실행되는 도중에는 컨텍스트 스위칭이 결코 일어날 수 없다. 이렇듯 모든 기계 명령은 원자적이다. 그럼에도 불구하고 TSL을 원자명령이라고 명명한 것은, 2개의 명령을 합쳐 1개의 명령으로 만들고 TSL 명령 실행 중간에 인터럽트 서비스나 컨텍스트 스위칭이 발생하지 못하도록 하였다는 것이다.
```

<hr>

출처
- [임계 구역 문제](https://ko.wikipedia.org/wiki/%EC%9E%84%EA%B3%84_%EA%B5%AC%EC%97%AD_%EB%AC%B8%EC%A0%9C)

<hr>

# 멀티스레드 동기화 기법
동기화 기법들은 겉으로 드러나지는 않지만, 임계구역에 진입할 때 상호배제를 위해 원자명령을 사용한다.
- 락(lock) 방식: 뮤텍스(mutex), 스핀락(spinlock)
- wait-signal 방식: 세마포(semaphore)

락 방식은 하나의 락 변수를 두고, 락을 잠근 스레드만이 임계구역에 진입하는 기법이다. 뮤텍스 기법은 락을 소유하지 않은 스레드를 대기 큐에서 재우고 락이 풀리기를 기다리게 하는 방식이고, 스핀락 기법은 락이 잠겨 있으면 락이 풀릴 때까지 무한 루프를 돌면서 락을 검사하는 코드를 실행하는 기법이다. 세마포는 여러 개의 공유 자원을 여러 스레드가 사용할 수 있도록 관리하는 기법이다.

## 뮤텍스
뮤텍스는 잠김/열림(locked/unlocked) 중 한 상태를 가지는 락 변수를 이용하여, 한 스레드만 임계구역에 진입시키고 다른 스레드들은 큐에 대기시키는 기법이다.
- 변수 - 락 변수
- 연산 - lock 연산과 unlock 연산
- 큐 - 대기 큐(wait queue)

뮤택스는, 락이 걸려 있는 경우 임계구역에 들어가려고 하는 스레드가 락이 풀릴 때까지 블록 상태로 대기 큐에서 잠을 자기 때문에 블록킹 락(blocking lock) 기법이라고도 하고, sleep-waiting lock 기법이라고도 한다.

### 락 변수
락 변수는 true와 false 중 한 값을 가지는 변수이다. 락 변수에 true를 저장하는 것을 '락을 잠근다', '락을 소유한다', 또는 '자원을 소유한다'고 표현한다. 락을 false로 만드는 것을 '락을 연다', '락을 푼다', 혹은 '락을 해제한다' 등으로 표현한다. <strong>락 변수를 true로 만든 스레드만 임계구역을 실행할 수 있다. </strong>

### lock 연산
lock 연산은 임계구역의 entry 코드로서, 락이 잠금(lock=true) 상태이면 현재 스레드를 블록 상태로 만들어 대기 큐에 삽입한다. 락이 잠금 상태가 아니면, 락을 잠그고 임계구역으로 진입한다. lock 연산의 구현에는 원자명령이 사용된다.

### unlock 연산
unlock 연산은 임계구역을 나올 때 실행하는 exit 코드로서, 락을 열림 상태(lock=false)로 변경하고 대기 큐에 있는 스레드 중 하나를 깨워 준비 상태로 만든다.

### 뮤텍스의 특징
임계구역의 실행시간이 짧은 경우, 뮤텍스는 비효율적이다. 락이 잠겨 있는 경우, 스레드는 CPU를 내놓고(컨텍스트 스위칭) 대기 큐로 들어가서 락이 풀리면 다시 CPU를 얻어(컨텍스트 스위칭) 실행된다. 임계구역의 실행시간이 짧으면, 락이 잠겨 있는 시간보다 스레드가 잠자고 깨는데 걸리는 시간 낭비(2번의 컨텍스트 스위칭)가 더 크기 때문에 비효율적이다.

## 스핀락(spinlock)
스핀락도 뮤텍스와 같이 락을 기반으로 하는 동기화 기법이지만, 뮤텍스와 달리 대기 큐가 없다. 
- 변수 - 락 변수
- 연산 - lock 연산과 unlock 연산

스핀락 기법에서, 스레드는 임계구역에 진입하기 위해 lock 연산을 실행한다. lock 연산은 락이 잠겨 있으면 뮤텍스와 달리 무한 루프를 돌며 락이 풀릴 때까지 락을 검사한다. 스레드는 타임 슬라이스가 다하게 되면 컨텍스트 스위칭 되고, 다시 스케줄되면 또 다시 lock 변수가 열림 상태가 될 때까지 루프를 돈다. 그래서 스핀락을 공격적인 뮤텍스(aggressive mutex)라고 한다. 스핀(spin) 용어 역시 락이 풀릴 때까지(자원을 얻을 때까지) 계속 락 변수를 감시하기 때문에 붙여졌다. 뮤텍스 기법을 sleep-waiting lock 기법이라고 하고, 스핀락을 busy-waiting lock 기법이라고 한다.

### 락 변수
스핀락 기법에서 락 변수를 스핀락이라고 한다. 스핀락을 소유한 스레드만 임계구역에 진입할 수 있다.

### lock 연산
lock 연산은 임계구역의 entry 코드로서, 락 변수가 열림 상태이면 락을 잠구고 임계구역에 들어선다. 만일 락이 잠금 상태이면 열릴 때까지 무한 루프를 돈다. 락이 열리면 락을 잠그고 임계구역에 들어간다. lock 연산의 구현에는 원자명령이 사용된다.

### unlock 연산 
unlock 연산은 임계구역을 나올 때 실행하는 exit 코드로서, 락을 열림으로 변경한다.

### 스핀락의 특징
- busy-waiting 모형
- 단일 CPU를 가진 운영체제에서 스핀락은 매우 비효율적이다. T1 스레드가 락을 잠구고 임계구역을 실행한다. CPU가 하나뿐이므로 운영체제는 T1 스레드를 중단시키고 T2를 스케줄링하여 실행시킨다. T2 스레드가 실행되었지만 락이 잠겨 있어, lock 연산은 락이 열림 상태가 될 때까지 락을 검사하는 코드를 실행하므로 계속 CPU를 사용한다. 결국 T2는 타임 슬라이스 내내 의미 없는 기다림에 CPU를 사용하기 때문에, CPU의 낭비가 심하고 다른 스레드의 실행 기회마저 뺐게 된다. 이런 이유로 스핀락은 단일 CPU를 가진 시스템에서 비효율적이다. 이와 대조적으로, 멀티코어 CPU 시스템의 경우, 락을 경쟁하는 스레드들은 서로 다른 코어에서 실행시키면 상당히 효과적이다.
- 스핀락은 임계구역 코드가 짧아서 락이 빨리 풀리는 경우에 매우 효과적이다. 스핀락을 이용하면 2번의 컨텍스트 스위칭(락을 얻지 못한 스레드를 블록시키는 컨텍스트 스위칭과 대기 큐에서 다시 실행시키는 컨텍스트 스위칭)이 필요없고, 이 사이에서 벌어지는 스케줄링 또한 필요없다.
- 스핀락은 스레드들이 락을 얻기 위해 무한 경쟁하기 때문에, 어떤 스레드가 불행하게도 무한 경쟁에서 오랜 동안 락을 얻지 못할 수도 있다. 즉 기아(starvation)를 발생할 수 있다. 또한 락을 소유한 스레드가 락을 풀어놓지 않고 종료하거나 코딩이 잘못되어 무한 루프를 도는 경우, 스핀락이 열리기를 기다리는 다른 스레드들은 무한정 CPU를 사용하면서 영원히 기다리게 될 수도 있다.
```
현대 컴퓨터는 대부분 멀티 코어 CPU를 장착하고 있으므로 리눅스 커널은 스레드 동기화의 기본 기법으로 스핀락을 사용하고 있다.
```

## 뮤텍스와 스핀락의 차이
- 대기큐: 뮤텍스는 있음 / 스핀락은 없음
- 블록 가능 여부: 뮤텍스는 락이 잠겨 있으면 블록됨(blocking) / 스핀락은 락이 잠겨 있어도 블록되지 않고 계속 락 검사(non-blocking)
- lock/unlock 연산 비용: 뮤텍스는 저비용 / 스핀락은 CPU를 계속 사용하므로 고비용
- 하드웨어 관련: 뮤텍스는 단일 CPU에 적합 / 스핀락은 멀티코어 CPU에 적합
- 주 사용처: 뮤텍스는 사용자 모드, 사용자 응용 프로그램 / 스핀락은 커널 모드, 커널 코드, 인터럽트 서비스 루틴

## 세마포(Semaphore)
세마포는 n개의 자원을 다수의 스레드가 공유하여 사용하도록 돕는 자원 관리 기법이다.
- 자원: n개
- 대기 큐: 자원을 할당받지 못한 스레드가 잠자는 곳
- counter 변수: 사용가능한 자원의 개수를 나타내는 정수형 변수로 자원의 개수 n으로 초기화된다. counter 변수가 음수이면 자원을 기다리는 스레드의 개수를 나타낸다. counter 변수를 구현하는 방법에 따라 사용가능한 자원이 없을 때 counter 변수를 계속 0으로 유지하기도 한다.
- P/V 연산: P 연산은 자원 요청 시, V 연산은 자원 반환 시 실행되는 연산

스레드가 자원의 개수보다 작으면 아무 문제가 없지만, 자원의 개수보다 클 때 스레드들 사이에서 자원을 할당하고 해제하는 등 자원 관리가 필요하며 이때 세마포가 유용하다. 

뮤텍스나 스핀락은 여러 스레드가 임계구역을 진입하기 위해 경쟁할 때, 한 스레드에게 임계구역을 배타적으로 사용하도록 하는데 목적이 있지만, 세마포는 n개의 자원이 있고 여러 스레드들이 자원을 사용하고자 할 때 원활하게 관리하는 것이 목적이다.

### P 연산과 V 연산
P/V 연산은 wait/signal 연산으로도 불린다. P 연산은 스레드의 자원 사용을 허가하는 과정이다. P 연산은 counter 변수를 1 감소시키고, V 연산은 counter 변수를 1 증가시킨다. 세마포는 자원을 할당받지 못하는 스레드를 다루는 방법에 따라 다음 2가지 종류로 나뉘며 P/V 연산 역시 다르게 작동한다.
- sleep-wait 세마포
- busy-waiting 세마포

sleep-wait 세마포는 P 연산 중 자원 사용을 허가받지 못한 스레드는 가용 자원이 생길 때까지 대기 큐에서 잠을 자고(sleep-wait), V 연산에 의해 사용가능한 자원이 생기게 되면 깨어나 자원을 획득하는 형태이다.

busy-waiting 세마포는 P 연산에서 가용 자원이 생길 때까지 무한 루프를 돌면서 검사(busy-waiting)하는 방식이다. 그러다가 V 연산에 의해 가용 자원이 생기면, P 연산에서 자원을 획득하는 방식이다. busy-waiting 세마포에는 대기 큐가 필요 없다.

P/V 연산이 wait-signal 연산이라고 불리는 이유는, 자원을 사용하려는 스레드는 대기 큐에 있든 무한루프를 돌든 자원을 얻을 때까지 대기(wait)하고, 자원 사용을 끝낸 스레드는 대기하는 스레드에게 이를 알려(signal) 자원에 대한 스레드 동기화를 이루기 때문이다.

```
P/V 연산과 원자 명령
counter 변수는 P/V 연산에 의해 동시에 접근되므로 상호배제가 필요하다. 사실상 P/V 연산에서 counter 변수에 대한 접근 코드가 임계구역이 되며 원자명령으로 구현된다. counter 변수를 세마포 변수라고 부른다.
```

## 이진 세마포
세마포는 관리하는 자원이 여러 개인 경우와 1개인 경우에 따라 다음과 같이 구분된다.
- 카운터 세마포(counter semaphore) - 자원이 여러 개인 경우
- 이진 세마포(binary semaphore) - 자원이 1개인 경우

이진 세마포를 구성하는 요소는 다음과 같다.
- 세마포 변수 S - 0과 1 중 하나를 가지는 변수. 1로 초기화됨
- 대기 큐 - 자원이 사용가능하게 될 대까지 스레드들이 대기하는 큐
- P 연산 - 자원 사용의 허가를 얻는 과정으로 S를 1 감소시키고 0보다 작으면 스레드를 대기 큐에서 잠들게 한다. 만일 S가 0보다 크거나 같으면 스레드는 자원을 사용하는 코드를 실행한다.
- V 연산 - 자원 사용이 끝났음을 알리는 과정으로, S를 1 증가시키고 0보다 크면 그냥 리턴하고, 0보다 작거나 같으면 대기 큐에 있는 스레드 중 하나를 깨운다.

이진 세마포는 하나의 자원에 대해 여러 스레드가 사용하고자 할 때 관리하는 기법으로 뮤텍스와 매우 유사하다.

<hr>

# RAID 
## RAID는 왜 사용되는가?
저장 장치의 성능과 신뢰성은 컴퓨터 시스템의 성능과 신뢰성에 직접 영향을 미치기 때문에 운영체제는 저장 장치를 효율적으로 제어할 필요가 있다.
- 저장 장치의 성능 - 입출력 병목(I/O bottleneck) 문제
- 저장 장치의 신뢰성 - 데이터의 신뢰성(data reliability) 문제
- 저장 장치의 입출력 병목

저장 장치의 입출력 병목은 입출력에 과부하가 걸려 있는 상태를 뜻한다. 여러 프로세스가 유발한 입출력 요청들로 인해, 저장 장치가 쉼 없이 작동하고 사용자나 프로세스는 입출력이 끝나기를 오래 대기하는 현상이다. 지난 몇 십년동안 CPU와 메모리의 처리 속도는 엄청난 발전을 거듭했지만 저장 장치의 속도 향상은 이에 미치지 못하여, 처리 능력 차이가 커지게 된 것이 저장 장치 병목의 원인이 되었다.

입출력 방목 현상이 나타나면, CPU의 유휴시간이 늘어나고 시스템 전체를 느리게 만든다. 입출력 병목을 줄이기 위해 다양한 방법들이 있다.
- 주기억장치 메모리 늘리기 -> 저장 장치 입출력 횟수 줄이기
- 디스크 캐시 늘리기 -> 입출력 응답 속도 높이기
- 디스크 스케줄링 -> 디스크의 물리적인 입출력 시간 줄이기
- SSD와 같은 빠른 저장 장치 사용
- RAID와 같은 병렬 저장 장치 사용
  
## RAID란 
Redudant Array of Inexpensive Disks의 약자로, 여러 개의 값싼 디스크를 병렬로 동작시키는 저장 장치다. 

여러 개의 하드 디스크에 일부 중복된 데이터를 나눠서 저장하는 기술이다. 중복된 데이터를 나눠서 저장하는 제일 큰 이유는 데이터를 안전하게 보호하기 위함에 있다. 데이터를 나누는 다양한 방법이 존재하며, 이 방법들을 레벨이라 하는데 레벨에 따라 저장장치의 신뢰성을 높이거나 전체적인 성능을 향상 시키는 등의 다양한 목적을 만족 시킬 수 있다.

### RAID의 목적
- 여러 개의 디스크 모듈을 하나의 대용량 디스크처럼 사용할 수 있게 하는 것
- 여러 개의 디스크 모듈에 데이터를 나누어서 한꺼번에 쓰고 한꺼번에 읽는 식으로 입출력 속도를 높이는 것
- 여러 개의 디스크를 모아서 하나의 디스크로 만들고 그 중 하나 혹은 그 이상의 디스크에 장애가 나더라도 최소한 데이터가 사라지는 것은 방지하자는 것

RAID에는 여러 종류에 RAID 레벨이 있는데 대표적인 RAID 구성 조합은 다음과 같다.

## RAID 0
<img src="../imgs/os-raid0.png">

- 데이터를 블록 단위로 분할해, 복수의 디스크에 분산하고 배치한다.
- 패리티(parity)에 대한 오버헤드가 없어 읽기·저장 속도가 높아진다.
- 단 어느 한 디스크에서 장애가 발생하면 데이터는 모두 손실 된다는 단점이 있다.

## RAID 1
<img src="../imgs/os-raid1.png">

- Mirror 구성 또는 Shadowing 이라고 불린다.
- 빠른 기록 속도와 함께 장애 복구 능력이 요구되는 경우에 많이 사용된다.
- 최소 2개의 디스크로 구성한다. 이것은 디스크 장애를 대비하여 백업용으로 다른 하나의 디스크를 동일하게 구성하는 것이다.
- 한 디스크에 기록되는 모든 데이터를 다른 디스크에 복사해 놓는 방법으로 복구 능력을 제공한다. 
- 하나의 디스크를 사용하는 것보다 약간 나은 정도의 성능을 제공한다. 단, 읽을 때는 조금 빠른 속도를 제공하지만 저장할 때는 속도가 약간 느려지기도 한다.
- 두 개의 디스크에 데이터가 동일하게 기록되므로 데이터의 복구 능력은 높지만 전체 용량의 절반이 여분의 데이터를 기록하기 위해 사용되기 때문에 저장 용량 당 단가가 비싸다는 단점이 있다.

## RAID 5
<img src="../imgs/os-raid5.png">

- Parity 정보를 모든 디스크에 나눠 기록한다.
- 여기서 말하는 Parity (패리티) 란? 디스크 장애 시 데이터를 재 구축하는데 사용할 수 있는 사전에 계산된 값으로 디스크의 4개 블록 중 3개는 데이터를 저장하는데 쓰고 나머지 하나는 Parity 영역으로 두는 것이다.
- 디스크 하나가 장애가 날 경우 Parity 영역을 이용해서 장애 난 디스크의 데이터를 복구해낸다.
- 따라서 문제가 발생할 경우, 컨트롤러가 정상적으로 운영되고 있는 다른 디스크로부터 손실된 데이터를 가져와 복구/재생 한다.
- Parity 를 담당하는 디스크가 병목 현상을 일으키지 않기 때문에 RAID 5는 멀티 프로세스 시스템과 같이 작은 데이터 기록이 수시로 발생할 경우 속도가 더 빠르다.
- 하지만 읽기 작업일 경우 각 드라이브에서 Parity 정보를 건너뛰어야 하기 때문에 조금 느릴 수 있다.
- 작고 Random한 입출력이 많은 경우 더 나은 성능을 제공하며 빠른 기록 속도가 필수적이지 않다면 일반적인 다중 사용자 환경을 위해 가장 좋은 선택이라고 볼 수 있다.
- Disk는 최소 3개, 일반적으로 5개 이상 필요하다.

## RAID 6
<img src="../imgs/os-raid6.png">

- RAID 5와 비슷하지만 다른 디스크들 값에 분포되어 있는 2차 Parity 구성을 포함함으로써 매우 높은 장애 대비 능력을 제공한다.
- 디스크가 최대 2개까지 장애가 나더라도 데이터의 손실이 발생하지 않는다.
- 하지만 Parity가 2개이다 보니 장애가 난 디스크와의 동기화가 RAID 5보다는 느리다.
- Disk는 최소 4개가 필요하다.

## RAID 0 + 1 (Striping & Mirroring)
<img src="../imgs/os-raid0+1.png">

- RAID 0+1 은 RAID 0의 빠른 속도와 RAID 1의 안정적인 복구 기능을 합쳐 놓은 방식이다.
- Disk는 최소 4개가 필요하다.
- 데이터가 입력되면 Striping 방식으로 두 개 이상의 Disk에 나눠서 저장하며 동시에 같은 형태로 다른 Disk에도 동일하게 저장된다.
- 여기서 Striping이란? 쉽게 말해 디스크 하나가 Block으로 이루어져 있는데, 이러한 Block들을 Strips라고 하며 이러한 Strips의 집합을 Stripe라고 한다. Striping이란 데이터를 물리적으로 넓게 퍼뜨리며 읽기/쓰기가 가능하게 하는 것을 말한다.
- 4개의 디스크로 RAID 0+1을 구성하면 2개의 디스크로 Striping 할 때의 쓰기 속도가 나오며 읽기 속도는 4개의 디스크에서 나눠서 읽어오기 때문에 보다 빠른 속도를 갖게 된다.
- Mirroring으로 똑같은 디스크 복사본(Hot spare)을 갖고 있기 때문에 장애가 발생하더라도 완벽한 복구가 가능하다. (전체 용량의 50%만 사용이 가능하다.)


<hr>

출처
- [RAID가 뭐에요?](https://www.dknyou.com/blog/?q=YToxOntzOjEyOiJrZXl3b3JkX3R5cGUiO3M6MzoiYWxsIjt9&bmode=view&idx=7342927&t=board)

<hr>

# Thrashing
## Thrashing이란
페이지 폴트를 처리하는데 대부분의 시간을 소비하는 상태 또는 상황이다. 

## Thrashing의 원인
- Thrashing은 운영체제 실행 성능에 영향을 미친다.
- Thrashing은 운영채재애소 심각한 성능 문제를 야기한다.
- CPU의 사용량이 적을 때, 프로세스 스케줄링 메커니즘은 여러 프로세스를 동시에 메모리에 적재하려고 시도하여 멀티 프로그래밍의 정도를 증가시킨다.
- 이 경우 메모리의 프로세스 수가 메모리에서 사용 가능한 프레임 수를 초과한다. 각 프로세스에는 작업할 프레임 수가 지정된다.
- 우선순위가 높은 프로세스가 메모리에 도착하고 현재 메모리 프레임이 비어있지 않으면, 프레임을 차지하고 있던 다른 프로세스가 보조 저장소로 이동하고 비어있는 프레임에 우선순위가 높은 프로세스가 할당된다.
- 메모리가 가득 차자마자 필요한 페이지를 교환하는 데 오랜 시간이 걸린다. 대부분의 프로세스가 페이지를 기다리고 있기 때문에 CPU 사용률이 떨어진다. 
- 결과적으로 높은 수준의 멀티 프로그래밍과 프레임 부족은 운영체제에서 스레싱이 발생되는 가장 일반적인 두 가지 이유다.

<img src="../imgs/os-thrashing.png">

- 프로세스에 너무 적은 프레임이 할당되면, page fault가 너무 많고 자주 발생한다. 
- 결과적으로 CPU에 의해 유용한 작업이 수행되지 않을 것이고 CPU 활용률은 급격하게 떨어질 것이다. 
- 그러면 장기 스케줄러는 메모리에 더 많은 프로세스를 로드하여 멀티 프로그래밍의 정도를 증가시킴으로써 CPU 활용률을 높이려 할 것이다.
- 이것은 CPU 사용률의 추가적인 감소를 초래하여 더 높은 page fault를 발생시키고 Thrashing을 발생시킨다.
  
## Locality Model
- 지역성(locality)는 함께 활발히 사용되는 페이지들의 집합이다. 한 프로세스가 실행될 때, 한 지역성에서 다른 지역성으로 이동한다. 
- 예를 들어 함수가 호출되면, 함수 호출 명령(지역 변수, 로컬 변수 등)에 대한 메모리 참조가 이루어지는 새로운 지역성을 정의한다. 마찬가지로 함수가 종료되면 프로세스는 이 지역성을 벗어난다.

## Techniques to handle: 
### 1. Working Set Model
- Working Set Model은 Locality Model 개념을 기반으로 한다. 
- 기본 원칙은 프로세스에 현재 지역성을 수용할 수 있는 충분한 프레임을 할당하면 프로세스가 새로운 지역성으로 이동할 때만 page fault가 발생한다는 것이다. 그러나 할당된 프레임이 현재 지역성의 크기보다 작으면 프로세스가 thrash 하게 될 수 있다.
- 이 모델에 따르면 매개 변수 A를 기준으로 working set은 가장 최근의 'A' 페이지 참조에서의 페이지 집합으로 정의된다. 그러므로 현재 사용 중인 모든 페이지는 항상 working set의 일부가 된다.
- working set의 정확도는 매개 변수 A의 값에 달라진다. A가 너무 크면 workings set들이 겹칠 수도 있다. 반면에 A의 값이 너무 작으면 지역성이 전체적으로 포함되지 않을 수 있다.

D가 프레임에 대한 총 수요이고, WSS가 프로세스 i에 대한 working set 크기라면

<img src="../imgs/os-workingset.png">

'm'이 메모리에 사용 가능한 프레임 수이라면 두 가지 가능성이 있다.
- (i) D > m : 총 수요가 프레임 수를 초과하면 일부 프로세스가 충분한 프레임을 얻지 못해 Thrashing이 발생한다.
- (ii) D <= m : Thrashing이 발생하지 않는다.

### 2. Page Fault Frequency

<img src="../imgs/os-pagefaultfrequency.png">

- Thrashing 처리에 보다 직접적인 접근 방식은 Page-Fault Frequency 개념을 사용하는 것이다.
- Page-Fault Rate를 제어하는 방식이다.
- 어떻게 제어하느냐, 하면 Page-Fault Rate에서 일정 기준 이상 올라가거나 내려갔을 때 어떤 조치를 취한다. 즉 상한선과 하한선을 정한다는 말이다.
- Page-Fault Rate가 너무 높으면 프로세스에 할당된 프레임 수가 너무 적다는 것을 나타낸다. 반면 Page-Fault Rate이 낮으면 프로세스에 프레임이 너무 많다는 것을 나타낸다.
- 만약 Page-Fault Rate가 하한선보다 낮게 되면, 프로세스에서 프레임을 제거할 수 있다. 마찬가지로 상한선 보다 높게 되면 프로세스에 더 많은 프레임을 할당할 수 있다.
- 비어있는 프레임이 없는데 Page-Fault Rate가 높다면, 일부 프로세스를 일시 중단하고 그들의 프레임을 다른 프로세스에게 재할당할 수 있다. 

<hr>

출처
- [Techniques to handle Thrashing
](https://www.geeksforgeeks.org/techniques-to-handle-thrashing/)

<hr>

# 프로세스 스케줄러
프로세스 스케줄링은 CPU에서 실행중인 프로세스를 제거하고 특정 전략을 기반으로 다른 프로세스를 선택하는 프로세스 관리자의 활동이다. 

프로세스 스케줄링은 멀티프로그래밍 운영체제에 필수적인 부분이다. 이러한 운영체제는 한 번에 하나 이상의 프로세스를 실행 가능한 메모리에 적재할 수 있으며 적재된 프로세스들은 시분할 다중화를 사용해 CPU를 공유한다.

프로세스 스케줄러에 3가지 종류가 있다. 
- 장기 스케줄러(Long Term or job scheduler)
- 단기 스케줄러(Short term or CPU scheduler)
- 중기 스케줄러(Medium-term scheduler)

## 프로세스 스케줄링하기 위한 Queue
프로세스를 스케줄링하기 위한 Queue에도 세 가지 종류가 존재한다.
- Job Queue: 현재 시스템 내에 있는 모든 프로세스의 집합
- Ready Queue: 현재 메모리 내에 있으면서 CPU를 잡아서 실행되기를 기다리는 프로세스의 집합
- Device Queue: Device I/O 작업을 대기하고 있는 프로세스의 집합

## 장기 스케줄러
- Ready Queue에 적재하는 메모리와 디스크 사이의 스케줄링을 담당하는 스케줄러
- 수행할 job이 10개, 메모리에는 6개 밖에 올릴 수 없는 상황. job 10개 중 6개를 골라서 올려야 하는데 이때 job을 고르는 역할을 하는 것이 장기 스케줄러. 따라서 job 스케줄러라고 불리기도 한다.
- 멀티프로그래밍의 정도를 제어한다, 즉 임의의 시점에서 준비 상태에 있는 프로세스의 수를 제어한다. == 메모리에 동시에 올라가 있는 프로세스의 수를 조절한다. 
- I/O bound 중심의 프로세스들과 CPU bound 프로세스들의 적절한 비율을 조절해 올린다. I/O 바인딩 작업은 입출력 작업에 많은 시간을 사용하는 반면, CPU 바인딩 프로세스는 CPU에 시간을 소비한다. 작업(job) 스케줄러는 둘 사이의 균형을 유지하여 효율성을 높인다.
- 프로세스의 상태를 New 에서 Ready 상태로 전환한다. 
- 가상 메모리가 나오면서 수행할 job 10개 중 6개 밖에 올릴 수 없는 상황은 나오지 않는다. 10개 중 10개를 다 올릴 수 있다. 

## 단기 스케줄러
- 장기 스케줄러를 통해서 job을 6개를 고른 상태. 실제 CPU가 수행하는 것은 하나. Ready Queue에 있는 job 중 하나를 골라야하는데 이걸 골라주는 스케줄러. 따라서 CPU 스케줄러라고 불리기도 한다.
- Running 상태에서 스케줄링하기 위해 Ready 상태에서 하나의 프로세스를 선택하는 역할을 한다. 
- 단기 스케줄러는 실행 중에 프로세스를 로드하지 않고 스케줄링할 프로세스만 선택한다. CPU 스케줄러는 높은 burst 시간 프로세스로 인해 기아가 발생하지 않도록 보장한다.
- Dispathcer는 단기 스케줄러에 의해 선택된 프로세스를 CPU에 로드하는 책임이 있다. Context Switching은 dispathcer에 의해서만 수행된다. 

Dispathcer는 다음을 수행한다.
1. Switching context.
2. Switching to user mode.
3. Jumping to the proper location in the newly loaded program.

## 중기 스케줄러
- 장기 스케줄러에 의해 10개 중 6개의 job을 올려서 수행중인 상태. CPU가 수행하려고 보니 감당하기엔 너무 많아 문제가 생겨 6개 중 2개를 내려보내면 상황이 해결될 것. 6개 중 뭘 내려보낼지 결정하는 것이 중기 스케줄러의 역할 
Swapper라고도 불린다.
- 프로세스를 중단하고 재개할 책임이 있다. 주로 swapping(프로세스를 메모리에서 디스크로 이동하거나 그 반대)을 한다.
- I/O 바운드와 CPU 바운드 간의 완벽한 균형을 유지하는데 도움을 준다. 그것은 멀티프로그래밍의 정도를 줄여준다. 

## 결론
가상 메모리 발달로 현재는 단기 스케줄러만 남아있다. 

<hr>

출처
- [Process Schedulers in Operating System](https://www.geeksforgeeks.org/process-schedulers-in-operating-system/)
- [장기스케줄러 vs 중기스케줄러 vs 단기스케줄러](https://jhnyang.tistory.com/372)

<hr>

# x86 과 x64의 차이
- 윈도우에서 32비트는 x86, 64비트는 x64라고 표시한다. 
- 32비트 컴퓨터, 32비트 CPU, 32비트 운영체제 속에 담긴 32비트는 어떤 의미인가? 32비트 CPU란 32개의 주소선을 가진 CPU라는 뜻이다. 그리고 이 32개의 주소선은 주소 버스에 연결되고, CPU는 32개의 주소선을 통해 주소를 출력하면 32비트의 주소가 주소 버스를 통해 메모리에게 전달된다.
- 주소선 한 가닥에는 하나의 비트가 전달된다. 메모리 읽기의 경우, CPU가 어떤 주소를 발생시키면 메모리는 주소 버스를 통해 주소를 전달받고 일정 시간 후에 해당 주소의 데이터를 데이터 버스에 내놓는다. 
- 32개의 주소선을 가진 CPU가 액세스할 수 있는 주소의 범위는 다음과 같다. `2^32개의 서로 다른 주소, 0 ~ 2^32 - 1 번지`
- 컴퓨터에서 한 번지의 크기는 1바이트이므로, 32비트가 액세스할 수 있는 메모리의 최대 크기는 다음과 같다. `2^32 바이트 = 4GB`
- IA-32 (Intel Architecture, 32-bit)는 모든 레지스터와 명령, I/O 공간 및 메모리가 32비트이다. 4GB의 메모리만 접근할 수 있다.
- IA-32의 64비트 확장이 여럿 제안되었는데, 보통 이들을 통칭하여 x64라 부른다. 대표적으로 완전히 새로운 설계를 사용하며 하위 호환성이 보장되지 않는 인텔의 IA-64와, IA-32와 호환되면서 64비트 명령을 추가한 AMD의 AMD64(x64)가 있다.


```
워드(word)
하나의 기계어 명령이나 연산을 통해 저장된 장치로부터 레지스터에 옮겨 놓을 수 있는 데이터 단위이다.

메모리에서 레지스터로 데이터를 옮기거나, ALU를 통해 데이터를 조작하거나 할 때, 하나의 명령어로 실행될 수 있는 데이터 처리 단위이다. 흔히 사용하는 32비트 CPU 라면 워드는 32비트가 된다.

```

<hr>

출처
- [x86](https://ko.wikipedia.org/wiki/X86)
- [워드](https://ko.wikipedia.org/wiki/%EC%9B%8C%EB%93%9C_(%EC%BB%B4%ED%93%A8%ED%8C%85))

<hr>

# Interprocess Communication (IPC)
## IPC이란
- Interprocess Communication (IPC)는 프로그램이 서로 데이터를 통신하고 활동을 동기화하는데 사용된다. 
- 세마포어, 공유 메모리 및 내부 메시지 큐 등이 있다.
- IPC는 두 개 이상의 개별 프로그램 또는 프로세스가 서로 통신하는 방법이다.
- 따라서 실제 Disk 기반 파일을 사용하는 것과 정보를 전달하기 위한 I/O 오버헤드를 피할 수 있다. 
- 자원을 create 또는 open 해서 사용하고 닫아야 한다. 자원은 소유자, 그룹, 사용 권한을 가진다. 자원을 제거할 때까지 자원은 계속 존재한다. 실제 Disk 기반 파일과 달리 세마포어, 메시지 큐, 공유메모리는 재부팅 후에도 유지되지 않는다.
  
## IPC를 사용하는 이유
- 프로그램 간에 대화가 필요할 때, 프로세스 간 저수준의 통신 세부사항을 관리하는 코드를 짜고 싶지 않을 때 IPC를 사용한다.
- 저수준의 통신 세부사항은 커널 루틴이기 때문에, 커널이 처리한다.

## 주요 IPC 방식
- 파일 - 디스크에 저장된 레코드 또는 파일 서버가 요청 시 합성한 레코드로, 여러 프로세스에서 액세스할 수 있다. 
- Signal - 한 프로세스에서 다른 프로세스로 전송되는 시스템 메시지로, 일반적으로 데이터를 전송하는 데 사용되지 않고 다른 프로세스를 원격으로 명령하는 데 사용된다.
- Socket - 네트워크 인터페이스를 통해 동일한 컴퓨터의 다른 프로세스 또는 네트워크의 다른 컴퓨터로 전송되는 데이터이다. Stream 기반(TCP) 또는 드물게 Message 기반(UDP, SCTP)이다. 
- Message queue - 소켓과 유사하지만 일반적으로 메시지 경계를 유지하는 데이터 스트림이다. 일반적으로 운영체제에 의해 구현되고 여러 프로세스가 직접 연결되지 않고 메시지 큐를 읽고 쓸 수 있게 한다.
- Pipe - 표준 입력 및 출력을 사용하는 단방향 데이터 채널이다. 프로세스 간의 양방향 통신은 두 개의 파이프를 사용한다. 프로세스가 여러 개이면 파이프 낭비가 심하다.
  - Anonymous pipe(익명파이프) - 외부 프로세스에서 사용할 수 없다. 부모 프로세스가 자식 프로세스를 생성하는 경우에 파일 지정 번호를 상속받아 익명파이프로 통신할 수 있다.
  - Named pipe(네임드파이프) - 외부 프로세스와 통신할 수 있다. 각 파이프에 이름과 권한을 부여해 파이프를 생성해준다. 읽기와 쓰기 모두 가능하지만 한 번에 한 방향으로만 통신이 가능한 반이중통신이다. 전이중통신을 위해서는 읽기파이프와 쓰기파이프 총 2개의 파이프를 생성해주어야 한다. 
- Shared memory - 여러개의 프로세스들이 동일한 메모리 블록에 대한 액세스 권한이 부여되어 프로세스가 서로 통신할 수 있는 공유 버퍼가 생성된다. 커널 의존성이 낮아 속도가 빠르다. 동일한 자원을 공유하기 때문에 동기화 이슈가 있다. 
- Message passing - 여러 프로그램이 메시지 큐 또는 non-OS 관리 채널을 사용하여 통신할 수 있다. 일반적으로 동시성 모델에 사용된다.
- Memory-mapped file - RAM에 매핑된 파일이며 스트림으로 출력하는 대신 메모리 주소를 직접 변경하여 수정할 수 있다.  


<hr>

출처
- [Inter Process Communication (IPC)](https://www.geeksforgeeks.org/inter-process-communication-ipc/)
- [프로세스 간 통신 방법(IPC)](https://dar0m.tistory.com/233)

<hr>