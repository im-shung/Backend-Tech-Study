# 운영체제

# 프로세스
## 프로그램과 프로세스 차이
프로그램(prgram)
- 하드디스크 등의 저장 매체에 저장
- 실행 파일의 형태

프로세스(prcess)
- 프로그램이 메모리에 적재되어 실행 중인 상태
  - 필요한 모든 자원을 할당 받는다.
  - 자원이란 코드/데이터/스택/힙 공간을 말한다.

## 프로세스 특징
- 운영체제는 프로그램을 메모리에 적재하고 프로세스로 다룬다.
- 운영체제는 프로세스에게 실행에 필요한 메모리를 할당한다. 이곳에 코드와 데이터 등을 적재한다.
- 프로세스들은 서로 독립적인 메모리 공간을 가진다. 다른 프로세스의 영역에 접근 불가능.

## 프로세스 관리
프로세스 생성에서 종료까지 관리는 모두 커널에 의해 이루어진다. 커널 영역에 프로세스 테이블을 만들고, 프로세스의 목록을 관리한다.

관리 내용
- 프로세스 생성/실행/일시중단/재개/중단
- 프로세스 정보 관리
  - 프로세스의 메모리 위치
  - 크기 
- 프로세스마다 고유한 번호(프로세스 ID)를 할당
- 프로세스 통신
- 프로세스 동기화
- 프로세스 컨텍스트 스위칭

## 프로그램의 다중 인스턴스
한 프로그램을 여러 번 실행시켜 다중 인스턴스를 생성할 수 있다. 운영체제는 프로그램을 실행할 때마다 독립된 프로세스를 생성한다. 각 프로세스는 독립된 메모리 공간이 할당된다. 

## 프로세스를 구성한 4개의 메모리 영역
### 코드(code) 영역
실행될 프로그램 코드가 적재되는 영역
- 사용자가 작성한 모든 함수 코드
- 사용자가 호출한 라이브러리 함수 코드

### 데이터(data) 영역
프로그램에서 고정적으로 만든 변수 공간으로 프로세스 적재 시 할당, 종료 시 소멸된다.
- 전역 변수 공간
- 정적 데이터 공간
- (사용자 프로그램과 라이브러리 포함)

### 힙(heap) 영역
프로세스가 실행 도중 동적으로 사용할 수 있도록 할당된 공간
- malloc() 등으로 할당받은 공간
  
힙 영역에서 아래 번지로 내려가며 할당된다.

### 스택(stack) 영역
함수가 실행될 때 사용될 데이터를 위해 할당된 공간
- 매개변수
- 지역변수
- 리턴값

함수는 호출될 때, 스택 영역에서 위쪽으로 공간을 할당한다. 함수가 return 하면 할당된 공간이 반환된다. 함수 호출 외에 프로세스에서 필요 시 사용가능하다.

## 프로세스 주소 공간
프로세스가 실행 중에 접근할 수 있도록 허용된 주소의 최대 범위이다. 

프로세스 주소 공간은 논리 공간(가상 공간)이다. 0번지에서 시작하여 연속적인 주소를 갖는다.

프로세스 주소 공간은 CPU가 액세스할 수 있는 전체 크기이다. (32 비트 CPU의 경우, 4GB)

### 프로세스 공간과 프로세스 현재 크기
프로세스 주소 공간의 크기는 프로세스의 현재 크기와 다르다.
- 프로세스 주소 공간 크기: 프로세스가 액세스할 수 있는 최대 크기
- 프로세스 현재 크기: 적재된 코드 + 전역 변수 + 힙 영역에서 할당받아 사용중인 동적 메모리 공간 + 현재 스택 영역에 저장된 데이터 크기

### 사용자 공간과 커널 공간
프로세스 주소 공간은 2부분으로 나뉘어진다.

사용자 공간
- 프로세스의 코드, 데이터, 힙, 스택 영역이 할당되는 공간
- 코드와 데이터 영역의 크기는 프로세스 시작 시 결정된다.
- 힙과 스택의 영역 크기는 정해져 있지 않다.
- 힙 영역은 아래로 자라고, 스택은 위로 자란다.
  
커널 공간
- 프로세스가 시스템 호출을 통해 이용하는 커널 공간
- 커널 코드, 커널 데이터, 커널 스택(커널이 실행될 때)
- 커널 공간은 모든 사용자 프로세스에 의해 공유된다.
  
### 가상 공간
프로세스 주소 공간은 사용자나 개발자가 보는 관점이다.
- 자신이 작성한 프로그램이 0번지부터 시작하여
- 연속적인 메모리 공간에 형성되고,
- CPU가 액세스할 수 있는 최대 크기의 메모리가 설치되어 있다고 상상

실제 상황
- 실제 물리 메모리 크기는 프로세스 주소 공간보다 작을 수 있다.
- 프로세스의 코드, 데이터, 힙, 스택 영역은 물리 메모리에 흩어져 저장된다. 연속적인 메모리 공간이 아니다.

# 커널의 프로세스 관리
## 프로세스 테이블과 프로세스 제어 블록
프로세스 테이블(Process Table) : 시스템의 모든 프로세스들을 관리하기 위한 표
- 시스템에 1개만 존재한다.
- 구현 방식은 OS마다 다르다.

프로세스 제어 블록(Process Control Block, PCB) : 프로세스에 관한 정보를 저장하는 구조체
- 프로세스당 1개씩 존재
- 프로세스가 생성될 때 만들어지고 종료되면 삭제된다.
- 커널에 의해 생성되고 저장, 읽혀지는 등 관리된다.

프로세스 테이블과 프로세스 제어 블록의 위치
- 커널 영역, 커널 코드(커널 모드)만이 액세스 가능

# 프로세스 생명 주기와 상태 변이(state change)
## 프로세스의 생명 주기
프로세스는 탄생에서 종료까지 여러 상태로 바뀌면서 실행된다.

<img src="../imgs/os-state-change.png">

## 프로세스의 상태
### New [생성 상태]
- 프로세스가 생성된 상태
- 메모리 할당 및 필요한 자원을 적재한다.

### Ready [준비 상태]
- 프로세스가 스케줄링을 기다리는 준비 상태
- 프로세스는 준비 큐에서 대기한다.
- [dispatch] 스케줄링되면 Running 상태로 바뀌고 CPU에 의해 실행된다.

### Running [실행 상태]
- 프로세스가 CPU에 의해 현재 실행되고 있는 상태
- [timeout] CPU의 시간할당량(타임슬라이스,time slice)가 지나면 다시 Ready 상태로 바뀌고 준비 큐에 삽입된다.
- [block] 프로세스가 입출력을 시행하면 커널은 프로세스를 Blocked 상태로 만들고 대기 큐에 삽입한다.

### Blocked/Wait [블록 상태]
- 프로세스가 자원을 요청하거나, 입출력 요청하고(시스템 호출) 완료를 기다리는 상태
- [wakeup] 입출력이 완료되면 프로세스는 Ready 상태로 바뀌고 준비 큐에 삽입된다.

### Terminated/Zombie 상태
- 프로세스가 종료된 상태
- 프로세스가 차지하고 있던 메모리와 할당받았던 자원을 모두 반환(열어 놓은 파일 닫힘)
- Zombie 상태: 프로세스의 PCB에 남긴 종료코드를 부모 프로세스가 읽어가지 않아 완전히 종료되지 않은 상태
  - 프로세스의 테이블 항목과 PCB가 시스템에 여전히 남아있는 상태

### Terminated/Out 상태
- 프로세스가 종료하면서 남긴 종료코드를 부모 프로세스가 읽어가서 완전히 종료된 상태
- 프로세스 테이블의 항목과 PCB가 시스템에서 완전히 제거된 상태

## 프로세스 스케줄링과 컨텍스트 스위칭 
과거 OS의 실행단위는 프로세스였다. Ready 상태의 프로세스 중 실행 시킬 프로세스를 선택했다.

오늘날 OS의 실행단위는 스레드다. Ready 상태의 스레드 중 실행 시킬 스레드를 선택한다.

프로세스는 스레드들에게 공유 자원을 제공하는 컨테이너(Container)로 역할이 바뀌었다. 

<hr>

# 인터럽트 
## 인터럽트란
프로세서가 현재 실행을 일시 중단하고 발생한 인터럽트를 서비스하도록 요청하는 신호이다. 인터럽트를 서비스하기 위해, 프로세서는 대응하는 인터럽트 서비스 루틴(ISR)을 실행한다. 인터럽트 서비스 루틴의 실행 후에, 프로세서는 정지된 프로그램의 실행을 재개한다. 

## 인터럽트가 필요한 이유
### 선점형 스케줄러 구현
프로세스를 교체하기 위해 스케줄러가 Running 상태인 프로세스를 중지시켜야 함

### IO Device와의 상호작용
저장 매체에서 데이터 처리 완료 시, 프로세스를 깨워야 함 (wakeup)

### 예외 상황 핸들링 
CPU가 프로그램을 실행하고 있을 때, 입출력 하드웨어 등의 장치나 예외상황이 발생할 경우, CPU가 해당 처리를 할 수 있도록 CPU에게 알려야 함

## 인터럽트 종류
### 하드웨어 인터럽트
장치들이 CPU에게 어떤 상황 발생을 알리는 하드웨어 신호다. 인터럽트가 발생하면 CPU는 인터럽트 서비스 루틴을 실행한다.
- I/O interrupt
- timer interrupt
- Maskable interrupt: 프로세서가 더 높은 우선순위로 프로그램을 실행할 경우 무시되거나 지연될 수 있다.
- Non Maskable interrupt: 무시되거나 지연될 수 없으며 프로세서에 의해 즉시 서비스되어야 한다.

### 소프트웨어 인터럽트
소프트웨어 인터럽트는 조건이 충족되거나 시스템 호출이 발생할 때 발생하는 인터럽트다. 어떤 경우에는 소프트웨어 인터럽트가 설계상이 아닌 프로그램 실행 오류에 의해 예기치 않게 발생할 수 있다. 이러한 인터럽트를 exceptions 또는 traps라고 한다. 

## 인터럽트 발생 처리 과정
<img src="../imgs/Instruction-Cycle-with-Interrupts.jpg">

일반적인 명령 주기는 명령 가져오기 및 실행으로 시작합니다. 그러나, 명령어의 정상적인 처리 중에 인터럽트가 발생하는 것을 수용하기 위해, 그림과 같이 인터럽트 사이클을 정상적인 명령 사이클에 추가한다.

현재 명령이 실행된 후, 프로세서는 인터럽트 신호를 확인하여 보류 중인 인터럽트가 있는지 확인합니다. 보류 중인 인터럽트가 없으면 프로세서는 시퀀스의 다음 명령을 가져오기 위해 계속한다. 

프로세서가 보류 중인 인터럽트를 발견하면, 실행되어야 하는 다음 명령어의 주소를 저장함으로써 현재 프로그램의 실행을 중단하고 프로그램 카운터(PC)를 인터럽트 서비스 루틴의 시작 주소로 업데이트하여 발생한 인터럽트를 서비스한다. 인터럽트가 완전히 서비스된 후 프로세서는 중단된 프로그램의 실행을 다시 시작합니다.

### 인터럽트 신호 허용
IE 플래그가 1로 설정되면 프로세서는 발생한 인터럽트를 허용합니다. IE 플래그가 0으로 설정된 경우 요청된 인터럽트를 무시합니다.

## 인터럽트 vs 폴링
폴링은 컴퓨터 시스템의 마이크로 컨트롤러가 모든 장치의 상태를 지속적으로 확인하는 지속적인 모니터링 상태이다. 마이크로 컨트롤러가 폴링을 하는 동안 다른 작업을 수행할 수 없기 때문에 낭비가 크다. 인터럽트를 사용하면 컨트롤러가 장치의 상태를 정기적으로 모니터링 할 필요가 없다. 인터럽트가 발생할 때만 응답하면 된다. 

<hr>

출처
- [Interrupts in Computer Architecture](https://binaryterms.com/interrupts-in-computer-architecture.html)
- [interrupt](https://www.techtarget.com/whatis/definition/interrupt)
- [인터럽트(Interrupt)란?](https://whatisthenext.tistory.com/147)

<hr>

# 캐시의 지역성(Locality)
## 캐시 메모리란
캐싱(caching)은 컴퓨터의 처리 성능을 높이기 위한 기법이다. CPU는 데이터를 처리하기 위해 메모리에 끊임없이 액세스 하는데, CPU에 비해 메모리 속도가 느려 CPU가 효율적으로 사용되지 못한다. 이를 해결하기 위해 CPU와 메모리 사이에 캐시를 두어 CPU의 메모리 액세스 횟수를 줄인다.

## 캐시 적중과 실패
캐시 메모리가 있는 컴퓨터 시스템은 CPU는 메모리에 접근하기 전에 캐시 메모리를 먼저 확인한다. 이때 필요한 데이터가 있는 경우 <strong>적중(hit)</strong>, 없는 경우를 <strong>실패(miss)</strong>라고 한다.

캐시에 저장할 데이터는 지역성을 가져야하는데 지역성이란 데이터 접근이 시간적 혹은 공간적으로 가깝게 일어나는 것을 말한다.

요청한 데이터를 캐시 메모리에서 찾을 확률을 <strong>적중률(hit ratio)</strong>라고 한다. 

캐시 메모리의 성능은 적중률에 의해 결정된다.
```
         캐시 메모리의 적중 횟수
적중률 = -----------------------
         전체 메모리의 참조 횟수
```

캐시 메모리의 적중 여부는 <strong>참조의 지역성(Locality of reference)</strong> 원리에 달려있다. 지역성이란 기억장치 내의 정보를 균일하게 접근하는 것이 아닌 어느 한 순간에 특성 부분을 집중적으로 참조하는 특성이다.

## 지역성의 종류
### 시간적 지역성(Temporal Locality)
특정 데이터가 한번 접근되었을 경우, 가까운 미래에 또 한번 데이터에 접근할 가능성이 높은 것.

메모리 상의 같은 주소에 여러 차례 읽기 쓰기를 수행할 경우, 상대적으로 작은 크기의 캐시를 사용해 효율성을 높일 수 있다.


### 공간적 지역성(Spatial Locality)
특정 데이터와 가까운 주소가 순서대로 접근되었을 경우.

CPU 캐시나 디스크 캐시의 경우 한 메모리 주소에 접근할 때 그 주소 뿐 아니라 해당 블록을 전부 캐시에 가져오게 된다. 이때 메모리 주소를 오름차순이나 내림차순으로 접근하면 캐시에 이미 저장된 같은 블록의 데이터를 접근하게 되므로 캐시 효율성이 향상된다.

### 순차적 지역성(Sequential Locality)
분기가 발생하지 않는 한 명령어는 메모리에 저장된 순서대로 인출/실행된다.

<hr>

출처
- [캐시 메모리(cache memory)의 개요 정리](https://zion830.tistory.com/46)
- [Caching Locality와 Cache Hit Ratio에 대해 설명하시오](https://github.com/lunchScreen/Interview_Questions/issues/98)

<hr>

# 뮤텍스와 세마포어 차이
## 임계영역과 상호배제
```
임계영역(Critical Section): 여러 프로세스가 데이터를 공유하며 수행될 때, 각 프로세스에서 공유 데이터를 접근하는 프로그램 코드 블록
```
```
상호 배제(Mutual Exclution): 임계 구역을 어느 시점에서 단지 한 개의 프로세스만이 사용할 수 있도록 하며, 다른 프로세스가 현재 사용 중인 임계 구역에 대하여 접근하려고 할 때 이를 금지하는 행위
```

프로세스 간 메시지를 전송하거나, 공유메모리를 통해 공유된 자원에 여러 개의 프로세스가 동시에 접근하면 임계영역 문제가 발생할 수 있다. 이를 해결하기 위해 <strong>데이터를 한 번에 하나의 프로세스만 접근할 수 있도록 제한을 두는 동기화 방식</strong>을 취해야 한다. 

동기화 도구에는 대표적으로 뮤텍스(Mutex)와 세마포어(Semaphore)가 있다. 이들은 모두 공유된 자원의 데이터를 여러 스레드/프로세스가 접근하는 것을 막는 역할을 한다.

## 뮤텍스 (Mutex)
공유된 자원의 데이터 혹은 임계영역(Critical Section) 등에 <strong>하나의 Process 혹은 Thread</strong>가 접근하는 것을 막아준다. 

-> 즉, 동기화 대상이 하나

임계영역(Critical Section)을 가진 스레드들의 실행시간(Running Time)이 서로 겹치치 않고 각각 단독으로 실행(상호배제)되도록 하는 기술이다. 



<img src="../imgs/os-mutex.png">

한 프로세스에 의해 소유될 수 있는 <strong>key를 기반으로 한 상호배제 기법</strong>이다. key에 해당하는 어떤 객체(object)가 있으며, <strong>이 객체를 소유한 스레드/프로세스만이 공유자원에 접근</strong>할 수 있다. 

다중 프로세스들의 공유 자원에 대한 접근을 조율하기 위해 <strong>동기화(Synchronization) 또는 락(Lock)</strong>을 사용함으로써 <strong>뮤텍스 객체를 두 스레드가 동시에 사용할 수 없다.</strong>

## 세마포어 (Semaphore)
공유된 자원의 데이터 혹은 임계영역(Critical Section) 등에 <strong>여러 Process 혹은 Thread</strong>가 접근하는 것을 막아준다. 

-> 즉, 동기화 대상이 하나 이상

<img src="../imgs/os-semaphore.png">

사용하고 있는 스레드/프로세스의 수를 <strong>공통으로 관리하는 하나의 값</strong>을 이용해 상호배제를 달성한다. 공유자원에 접근할 수 있는 <strong>프로세스의 최대 허용치만큼 동시에 사용자가 접근</strong>할 수 있으며, <strong>각 프로세스는 세마포어의 값을 확인하고 변경</strong>할 수 있다. 

자원을 사용하지 않는 상태가 될 때, 대기하던 프로세스가 즉시 자원을 사용한다. 이미 다른 프로세스에 의해 사용 중이라는 사실을 알게 되면, 재시도 전에 일정시간 대기해야 한다.

## 차이점
가장 큰 차이점은 <strong>동기화 대상의 개수</strong>이다.

Mutex
- 동기화 대상이 오직 1개일 때 사용한다.
- 자원을 소유하고 책임을 갖는다.
- 상태가 0, 1 뿐이므로 Lock을 가질 수 있고, 소유하고 있는 스레드만이 Mutex를 해제할 수 있다.
- 프로세스의 범위를 가지며 프로세스 종료될 때 자동으로 Clean up 된다.

Semaphore
- 동기화 대상이 1개 이상일 때 사용한다.
- 자원 소유가 불가하다.
- Semaphore를 소유하지 않는 스레드가 Semaphore를 해제할 수 있다.
- 시스템 범위에 걸쳐 있고, 파일 시스템 상의 파일로 존재한다.


## 결론
뮤텍스와 세마포어 모두 완벽한 기법은 아니므로, 데이터 무결성을 보장할 수 없고 모든 교착상태를 해결하지 못한다. 하지만 상호배제를 위한 기본적인 문법이며 여기에 좀 더 복잡한 매커니즘을 적용해 개선된 성능을 가질 수 있도록 하는 것이 중요하다.

<hr>

출처
- [Mutex 뮤텍스와 Semaphore 세마포어의 차이](https://heeonii.tistory.com/14)

<hr>

# 동기(Sync)와 비동기(Async) 차이
## 동기(Synchronous: 동시에 일어나는)
- 단일 스레드 모델
- 작업이 하나씩 순서대로 수행된다.
- 첫번째 작업이 완료되야지 다음 작업이 수행된다. 
- 블로킹 아키텍처로 반응성 시스템 프로그래밍에 적합하다.
- ex) 전화 

## 비동기(Asynchronous : 동시에 일어나지 않는)
- 멀티 스레드 모델
- 하나 이상의 작업이 진행되는 동안 추가적인 작업을 차단하지 않는다.
- 다른 작업이 완료될 때까지 기다리지 않고 여러 관련 작업을 동시에 실행할 수 있다.
- 함수가 호출될 때부터 함수의 값이 반환될 때까지의 지연 시간을 줄인다. 
  - 사용자는 자신의 앱이 빠르게 실행되기를 원하지만, API에서 데이터를 가져오는 데는 시간이 걸린다. 이러한 경우 비동기식 프로그래밍은 앱 화면이 더 빨리 로드되도록 도와주어 사용자 경험을 향상시킨다. 
- 논블로킹 아키텍처로 네트워킹 및 통신 프로그래밍에 적합하다.
- ex) 문자 메시지


## 차이점
Sync
- 단일 스레드로 한 번에 하나의 작업/프로그램만 실행된다.
- 서버에 한 번에 하나의 요청만 보내고, 해당 요청이 서버에 의해 응답될 때까지 기다린다.
- 속도가 느리지만 체계적이다.

Async
- 멀티 스레드로 여러 작업이나 프로그램이 병렬로 실행된다.
- 서버에 여러 요청을 전송한다.
- 여러 작업을 동시에 실행할 수 있어 처리량이 증가한다.

<hr>

출처
- [Asynchronous vs. Synchronous Programming](https://www.mendix.com/blog/asynchronous-vs-synchronous-programming/)